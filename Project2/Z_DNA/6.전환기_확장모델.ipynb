{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 확장기 변수를 활용해 전체 데이터셋, 전환기 데이터셋 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats.mstats import winsorize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "rc('font', family='Malgun Gothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# from matplotlib import rc\n",
    "# rc('font', family='AppleGothic')\n",
    "# plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "expansion_normal_win = pd.read_csv('../Data/WIN/expansion_normal_win.csv',encoding='CP949')\n",
    "recession_normal_win = pd.read_csv('../Data/WIN/recession_normal_win.csv',encoding='CP949')\n",
    "transition_normal_win =  pd.read_csv('../Data/WIN/transition_normal_win.csv',encoding='CP949')\n",
    "expansion_default_win =  pd.read_csv('../Data/WIN/expansion_default_win.csv',encoding='CP949')\n",
    "recession_default_win = pd.read_csv('../Data/WIN/recession_default_win.csv',encoding='CP949')\n",
    "transition_default_win =  pd.read_csv('../Data/WIN/transition_default_win.csv',encoding='CP949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_normal = pd.read_csv('../Data/WIN/transition_normal_win.csv',encoding='cp949')\n",
    "transition_default = pd.read_csv('../Data/WIN/transition_default_win.csv',encoding='cp949')\n",
    "transition = pd.concat([transition_normal,transition_default],axis=0)\n",
    "\n",
    "transition_00 = transition[transition['회계년도']==2000]\n",
    "transition_01 = transition[transition['회계년도']==2001]\n",
    "transition_05 = transition[transition['회계년도']==2005]\n",
    "transition_11 = transition[transition['회계년도']==2011]\n",
    "transition_13 = transition[transition['회계년도']==2013]\n",
    "transition_17 = transition[transition['회계년도']==2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "expansion = pd.concat([expansion_normal_win, expansion_default_win], axis=0)\n",
    "recession = pd.concat([recession_normal_win,recession_default_win], axis=0)\n",
    "transition = pd.concat([transition_normal_win,transition_default_win],axis=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "recession.iloc[:,3:-1]=scaler.fit_transform(recession.iloc[:,3:-1])\n",
    "\n",
    "# normal = recession[recession['부도']==0]\n",
    "# default = recession[recession['부도']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "student's t test Result\n",
      " ------------------------\n",
      " 매출채권회전률 등분산 t값은 2.114 이다. \n",
      " 매출채권회전률 등분산 p값은 0.035 이다. \n",
      "\n",
      "\n",
      "student's t test Result\n",
      " ------------------------\n",
      " 매입채무회전률 등분산 t값은 2.515 이다. \n",
      " 매입채무회전률 등분산 p값은 0.012 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " 유동비율 이분산 t값은 8.434 이다. \n",
      " 유동비율 이분산 p값은 0.000 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " 차입금의존도 이분산 t값은 -7.992 이다. \n",
      " 차입금의존도 이분산 p값은 0.000 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " 매출액증가율 이분산 t값은 2.796 이다. \n",
      " 매출액증가율 이분산 p값은 0.007 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " 매출액총이익률 이분산 t값은 5.651 이다. \n",
      " 매출액총이익률 이분산 p값은 0.000 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " 매출액영업이익률 이분산 t값은 7.210 이다. \n",
      " 매출액영업이익률 이분산 p값은 0.000 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " 매출액순이익률 이분산 t값은 6.101 이다. \n",
      " 매출액순이익률 이분산 p값은 0.000 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " 총자본영업이익률 이분산 t값은 10.142 이다. \n",
      " 총자본영업이익률 이분산 p값은 0.000 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " 자기자본순이익률 이분산 t값은 5.829 이다. \n",
      " 자기자본순이익률 이분산 p값은 0.000 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " 당좌비율 이분산 t값은 6.872 이다. \n",
      " 당좌비율 이분산 p값은 0.000 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " 부채비율 이분산 t값은 -3.190 이다. \n",
      " 부채비율 이분산 p값은 0.002 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " 총자본회전률 이분산 t값은 7.622 이다. \n",
      " 총자본회전률 이분산 p값은 0.000 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " RETA 이분산 t값은 7.927 이다. \n",
      " RETA 이분산 p값은 0.000 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " TLTA 이분산 t값은 -7.082 이다. \n",
      " TLTA 이분산 p값은 0.000 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " 이자보상배율 이분산 t값은 24.433 이다. \n",
      " 이자보상배율 이분산 p값은 0.000 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " vol유동비율 이분산 t값은 3.011 이다. \n",
      " vol유동비율 이분산 p값은 0.004 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " vol매출액총이익률 이분산 t값은 2.431 이다. \n",
      " vol매출액총이익률 이분산 p값은 0.018 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " vol매출액영업이익률 이분산 t값은 4.354 이다. \n",
      " vol매출액영업이익률 이분산 p값은 0.000 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " vol총자본영업이익률 이분산 t값은 3.686 이다. \n",
      " vol총자본영업이익률 이분산 p값은 0.000 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " vol당좌비율 이분산 t값은 3.049 이다. \n",
      " vol당좌비율 이분산 p값은 0.003 이다. \n",
      "welch's t test Result\n",
      " ------------------------\n",
      " vol이자보상배율 이분산 t값은 5.136 이다. \n",
      " vol이자보상배율 이분산 p값은 0.000 이다. \n",
      "['매출채권회전률', '매입채무회전률', '유동비율', '차입금의존도', '매출액증가율', '매출액총이익률', '매출액영업이익률', '매출액순이익률', '총자본영업이익률', '자기자본순이익률', '당좌비율', '부채비율', '총자본회전률', 'RETA', 'TLTA', '이자보상배율', 'vol유동비율', 'vol매출액총이익률', 'vol매출액영업이익률', 'vol총자본영업이익률', 'vol당좌비율', 'vol이자보상배율']\n"
     ]
    }
   ],
   "source": [
    "# Levene's test \n",
    "from scipy import stats\n",
    "from scipy.stats import levene\n",
    "levene_list = []\n",
    "expansion_list_pick = []\n",
    "expansion_list_drop = []\n",
    "\n",
    "for col in expansion_normal_win.iloc[:,3:-1].columns: \n",
    "    a = levene(expansion_normal_win.loc[:,col],expansion_default_win.loc[:,col])\n",
    "    levene_list.append(a)\n",
    "\n",
    "expansion_df = pd.DataFrame(levene_list, index= expansion_normal_win.iloc[:,3:-1].columns)\n",
    "s_t_test = expansion_df[expansion_df['pvalue']>0.05] #H0 귀무가설을 채택 => 등분산성\n",
    "w_t_test = expansion_df[expansion_df['pvalue']<=0.05] #H1 귀무가설 기각 => 이분산성 \n",
    "\n",
    "for col in s_t_test.loc[:,'pvalue'].index:\n",
    "    s_t, s_p = stats.ttest_ind(expansion_normal_win.loc[:,col], expansion_default_win.loc[:,col], equal_var= True)\n",
    "                                                                                    #equal_var= False : 이분산 \n",
    "                                                                                    #equal_var= True : 등분산\n",
    "    if s_p <= 0.05 :\n",
    "        print('\\n')\n",
    "        print(\"student's t test Result\\n ------------------------\")\n",
    "        print(f' {col} 등분산 t값은 {s_t:.3f} 이다. ')\n",
    "        print(f' {col} 등분산 p값은 {s_p:.3f} 이다. ')\n",
    "        expansion_list_pick.append(col)\n",
    "    else:\n",
    "        expansion_list_drop.append(col)\n",
    "\n",
    "from scipy import stats\n",
    "for col in w_t_test.loc[:,'pvalue'].index:\n",
    "    w_t, w_p = stats.ttest_ind(expansion_normal_win.loc[:,col], expansion_default_win.loc[:,col], equal_var= False)\n",
    "    if w_p <= 0.05 :\n",
    "        print(\"welch's t test Result\\n ------------------------\")\n",
    "        print(f' {col} 이분산 t값은 {w_t:.3f} 이다. ')\n",
    "        print(f' {col} 이분산 p값은 {w_p:.3f} 이다. ')  \n",
    "        expansion_list_pick.append(col)\n",
    "    else:\n",
    "        expansion_list_drop.append(col)\n",
    "\n",
    "print(expansion_list_pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['매출채권회전률',\n",
       " '매입채무회전률',\n",
       " '유동비율',\n",
       " '차입금의존도',\n",
       " '매출액증가율',\n",
       " '매출액총이익률',\n",
       " '매출액영업이익률',\n",
       " '매출액순이익률',\n",
       " '총자본영업이익률',\n",
       " '자기자본순이익률',\n",
       " '당좌비율',\n",
       " '부채비율',\n",
       " '총자본회전률',\n",
       " 'RETA',\n",
       " 'TLTA',\n",
       " '이자보상배율',\n",
       " 'vol유동비율',\n",
       " 'vol매출액총이익률',\n",
       " 'vol매출액영업이익률',\n",
       " 'vol총자본영업이익률',\n",
       " 'vol당좌비율',\n",
       " 'vol이자보상배율']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expansion_list_pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_lst =['회사명', '거래소코드', '회계년도','매출채권회전률',\n",
    " '매입채무회전률',\n",
    " '유동비율',\n",
    " '차입금의존도',\n",
    " '매출액증가율',\n",
    " '매출액총이익률',\n",
    " '매출액영업이익률',\n",
    " '매출액순이익률',\n",
    " '총자본영업이익률',\n",
    " '자기자본순이익률',\n",
    " '당좌비율',\n",
    " '부채비율',\n",
    " '총자본회전률',\n",
    " 'RETA',\n",
    " 'TLTA',\n",
    " '이자보상배율',\n",
    " 'vol유동비율',\n",
    " 'vol매출액총이익률',\n",
    " 'vol매출액영업이익률',\n",
    " 'vol총자본영업이익률',\n",
    " 'vol당좌비율',\n",
    " 'vol이자보상배율','부도']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>거래소코드</th>\n",
       "      <th>회계년도</th>\n",
       "      <th>매출채권회전률</th>\n",
       "      <th>매입채무회전률</th>\n",
       "      <th>유동비율</th>\n",
       "      <th>차입금의존도</th>\n",
       "      <th>매출액증가율</th>\n",
       "      <th>매출액총이익률</th>\n",
       "      <th>매출액영업이익률</th>\n",
       "      <th>...</th>\n",
       "      <th>RETA</th>\n",
       "      <th>TLTA</th>\n",
       "      <th>이자보상배율</th>\n",
       "      <th>vol유동비율</th>\n",
       "      <th>vol매출액총이익률</th>\n",
       "      <th>vol매출액영업이익률</th>\n",
       "      <th>vol총자본영업이익률</th>\n",
       "      <th>vol당좌비율</th>\n",
       "      <th>vol이자보상배율</th>\n",
       "      <th>부도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2002</td>\n",
       "      <td>18.91</td>\n",
       "      <td>58.88</td>\n",
       "      <td>114.21</td>\n",
       "      <td>53.16</td>\n",
       "      <td>66.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-14.46</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139228</td>\n",
       "      <td>0.575696</td>\n",
       "      <td>-9.989503</td>\n",
       "      <td>-26.80</td>\n",
       "      <td>-14.35</td>\n",
       "      <td>-16.32</td>\n",
       "      <td>-16.39</td>\n",
       "      <td>-3.29</td>\n",
       "      <td>-11.021527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2006</td>\n",
       "      <td>2.50</td>\n",
       "      <td>6.22</td>\n",
       "      <td>232.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-20.58</td>\n",
       "      <td>3.74</td>\n",
       "      <td>-35.59</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.896302</td>\n",
       "      <td>0.296247</td>\n",
       "      <td>-14.082157</td>\n",
       "      <td>136.87</td>\n",
       "      <td>13.35</td>\n",
       "      <td>12.07</td>\n",
       "      <td>14.13</td>\n",
       "      <td>143.03</td>\n",
       "      <td>-0.677342</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2010</td>\n",
       "      <td>2.71</td>\n",
       "      <td>7.41</td>\n",
       "      <td>306.73</td>\n",
       "      <td>8.48</td>\n",
       "      <td>11.86</td>\n",
       "      <td>23.74</td>\n",
       "      <td>-53.88</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.896302</td>\n",
       "      <td>0.289649</td>\n",
       "      <td>-7.334934</td>\n",
       "      <td>198.14</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>19.58</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>148.77</td>\n",
       "      <td>0.950721</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.95</td>\n",
       "      <td>5.27</td>\n",
       "      <td>325.47</td>\n",
       "      <td>2.65</td>\n",
       "      <td>11.96</td>\n",
       "      <td>37.07</td>\n",
       "      <td>1.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.896302</td>\n",
       "      <td>0.155866</td>\n",
       "      <td>3.630886</td>\n",
       "      <td>-233.86</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-206.21</td>\n",
       "      <td>2.905378</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.66</td>\n",
       "      <td>297.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.85</td>\n",
       "      <td>36.26</td>\n",
       "      <td>-9.51</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.896302</td>\n",
       "      <td>0.171743</td>\n",
       "      <td>-18.504432</td>\n",
       "      <td>-27.72</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-11.47</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>-33.02</td>\n",
       "      <td>-35.835295</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>잘만테크(주)</td>\n",
       "      <td>90120</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.56</td>\n",
       "      <td>3.24</td>\n",
       "      <td>50.12</td>\n",
       "      <td>56.44</td>\n",
       "      <td>-59.33</td>\n",
       "      <td>6.84</td>\n",
       "      <td>-53.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.861568</td>\n",
       "      <td>0.952132</td>\n",
       "      <td>-6.782718</td>\n",
       "      <td>-79.98</td>\n",
       "      <td>-7.70</td>\n",
       "      <td>-57.55</td>\n",
       "      <td>-31.35</td>\n",
       "      <td>-72.53</td>\n",
       "      <td>-8.624891</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>제이앤유글로벌</td>\n",
       "      <td>86200</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.69</td>\n",
       "      <td>7.07</td>\n",
       "      <td>159.68</td>\n",
       "      <td>16.90</td>\n",
       "      <td>30.06</td>\n",
       "      <td>29.86</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096090</td>\n",
       "      <td>0.534729</td>\n",
       "      <td>-0.361713</td>\n",
       "      <td>44.91</td>\n",
       "      <td>21.73</td>\n",
       "      <td>21.37</td>\n",
       "      <td>8.50</td>\n",
       "      <td>25.50</td>\n",
       "      <td>4.805396</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>평안물산(주)</td>\n",
       "      <td>37240</td>\n",
       "      <td>2010</td>\n",
       "      <td>5.98</td>\n",
       "      <td>58.51</td>\n",
       "      <td>267.09</td>\n",
       "      <td>14.18</td>\n",
       "      <td>-49.19</td>\n",
       "      <td>-61.15</td>\n",
       "      <td>-171.19</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.183320</td>\n",
       "      <td>0.197237</td>\n",
       "      <td>-18.565483</td>\n",
       "      <td>149.06</td>\n",
       "      <td>-44.72</td>\n",
       "      <td>-94.72</td>\n",
       "      <td>-9.98</td>\n",
       "      <td>149.43</td>\n",
       "      <td>-10.641540</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>퓨쳐비젼(주)</td>\n",
       "      <td>42570</td>\n",
       "      <td>2007</td>\n",
       "      <td>2.52</td>\n",
       "      <td>58.51</td>\n",
       "      <td>14.61</td>\n",
       "      <td>57.72</td>\n",
       "      <td>-11.99</td>\n",
       "      <td>-5.22</td>\n",
       "      <td>-97.90</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.394696</td>\n",
       "      <td>1.696991</td>\n",
       "      <td>-41.181406</td>\n",
       "      <td>-1932.08</td>\n",
       "      <td>-15.02</td>\n",
       "      <td>-44.05</td>\n",
       "      <td>-14.14</td>\n",
       "      <td>-1667.67</td>\n",
       "      <td>22.597350</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>한국통신데이타(주)</td>\n",
       "      <td>45760</td>\n",
       "      <td>2007</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.74</td>\n",
       "      <td>347.91</td>\n",
       "      <td>10.33</td>\n",
       "      <td>37.06</td>\n",
       "      <td>25.27</td>\n",
       "      <td>-86.67</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.041814</td>\n",
       "      <td>0.380736</td>\n",
       "      <td>-10.717970</td>\n",
       "      <td>-117.41</td>\n",
       "      <td>25.27</td>\n",
       "      <td>68.05</td>\n",
       "      <td>23.15</td>\n",
       "      <td>-123.04</td>\n",
       "      <td>22.597350</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7241 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           회사명  거래소코드  회계년도  매출채권회전률  매입채무회전률    유동비율  차입금의존도  매출액증가율  \\\n",
       "0     (주)CMG제약  58820  2002    18.91    58.88  114.21   53.16   66.81   \n",
       "1     (주)CMG제약  58820  2006     2.50     6.22  232.13    0.00  -20.58   \n",
       "2     (주)CMG제약  58820  2010     2.71     7.41  306.73    8.48   11.86   \n",
       "3     (주)CMG제약  58820  2014     1.95     5.27  325.47    2.65   11.96   \n",
       "4     (주)CMG제약  58820  2015     2.10     5.66  297.75    0.00   18.85   \n",
       "..         ...    ...   ...      ...      ...     ...     ...     ...   \n",
       "59     잘만테크(주)  90120  2014     1.56     3.24   50.12   56.44  -59.33   \n",
       "60     제이앤유글로벌  86200  2015     3.69     7.07  159.68   16.90   30.06   \n",
       "61     평안물산(주)  37240  2010     5.98    58.51  267.09   14.18  -49.19   \n",
       "62     퓨쳐비젼(주)  42570  2007     2.52    58.51   14.61   57.72  -11.99   \n",
       "63  한국통신데이타(주)  45760  2007     1.50     2.74  347.91   10.33   37.06   \n",
       "\n",
       "    매출액총이익률  매출액영업이익률  ...      RETA      TLTA     이자보상배율  vol유동비율  \\\n",
       "0      0.00    -14.46  ... -0.139228  0.575696  -9.989503   -26.80   \n",
       "1      3.74    -35.59  ... -0.896302  0.296247 -14.082157   136.87   \n",
       "2     23.74    -53.88  ... -0.896302  0.289649  -7.334934   198.14   \n",
       "3     37.07      1.96  ... -0.896302  0.155866   3.630886  -233.86   \n",
       "4     36.26     -9.51  ... -0.896302  0.171743 -18.504432   -27.72   \n",
       "..      ...       ...  ...       ...       ...        ...      ...   \n",
       "59     6.84    -53.39  ... -0.861568  0.952132  -6.782718   -79.98   \n",
       "60    29.86     -0.98  ...  0.096090  0.534729  -0.361713    44.91   \n",
       "61   -61.15   -171.19  ... -3.183320  0.197237 -18.565483   149.06   \n",
       "62    -5.22    -97.90  ... -3.394696  1.696991 -41.181406 -1932.08   \n",
       "63    25.27    -86.67  ... -2.041814  0.380736 -10.717970  -117.41   \n",
       "\n",
       "    vol매출액총이익률  vol매출액영업이익률  vol총자본영업이익률  vol당좌비율  vol이자보상배율   부도  \n",
       "0       -14.35       -16.32       -16.39    -3.29 -11.021527  0.0  \n",
       "1        13.35        12.07        14.13   143.03  -0.677342  0.0  \n",
       "2        -0.59        19.58        -1.60   148.77   0.950721  0.0  \n",
       "3        -1.39        -2.09        -0.68  -206.21   2.905378  0.0  \n",
       "4        -0.81       -11.47        -5.26   -33.02 -35.835295  0.0  \n",
       "..         ...          ...          ...      ...        ...  ...  \n",
       "59       -7.70       -57.55       -31.35   -72.53  -8.624891  1.0  \n",
       "60       21.73        21.37         8.50    25.50   4.805396  1.0  \n",
       "61      -44.72       -94.72        -9.98   149.43 -10.641540  1.0  \n",
       "62      -15.02       -44.05       -14.14 -1667.67  22.597350  1.0  \n",
       "63       25.27        68.05        23.15  -123.04  22.597350  1.0  \n",
       "\n",
       "[7241 rows x 26 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expansion = expansion[pick_lst]\n",
    "expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "expansion_x = expansion.iloc[:,3:-1]\n",
    "expansion_y = expansion['부도']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>매출채권회전률</th>\n",
       "      <th>매입채무회전률</th>\n",
       "      <th>유동비율</th>\n",
       "      <th>차입금의존도</th>\n",
       "      <th>매출액증가율</th>\n",
       "      <th>매출액총이익률</th>\n",
       "      <th>매출액영업이익률</th>\n",
       "      <th>매출액순이익률</th>\n",
       "      <th>총자본영업이익률</th>\n",
       "      <th>자기자본순이익률</th>\n",
       "      <th>...</th>\n",
       "      <th>총자본회전률</th>\n",
       "      <th>RETA</th>\n",
       "      <th>TLTA</th>\n",
       "      <th>이자보상배율</th>\n",
       "      <th>vol유동비율</th>\n",
       "      <th>vol매출액총이익률</th>\n",
       "      <th>vol매출액영업이익률</th>\n",
       "      <th>vol총자본영업이익률</th>\n",
       "      <th>vol당좌비율</th>\n",
       "      <th>vol이자보상배율</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.91</td>\n",
       "      <td>58.88</td>\n",
       "      <td>114.21</td>\n",
       "      <td>53.16</td>\n",
       "      <td>66.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-14.46</td>\n",
       "      <td>-8.54</td>\n",
       "      <td>-18.98</td>\n",
       "      <td>-29.43</td>\n",
       "      <td>...</td>\n",
       "      <td>1.45</td>\n",
       "      <td>-0.139228</td>\n",
       "      <td>0.575696</td>\n",
       "      <td>-9.989503</td>\n",
       "      <td>-26.80</td>\n",
       "      <td>-14.35</td>\n",
       "      <td>-16.32</td>\n",
       "      <td>-16.39</td>\n",
       "      <td>-3.29</td>\n",
       "      <td>-11.021527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.50</td>\n",
       "      <td>6.22</td>\n",
       "      <td>232.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-20.58</td>\n",
       "      <td>3.74</td>\n",
       "      <td>-35.59</td>\n",
       "      <td>-102.58</td>\n",
       "      <td>-12.93</td>\n",
       "      <td>-65.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.896302</td>\n",
       "      <td>0.296247</td>\n",
       "      <td>-14.082157</td>\n",
       "      <td>136.87</td>\n",
       "      <td>13.35</td>\n",
       "      <td>12.07</td>\n",
       "      <td>14.13</td>\n",
       "      <td>143.03</td>\n",
       "      <td>-0.677342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.71</td>\n",
       "      <td>7.41</td>\n",
       "      <td>306.73</td>\n",
       "      <td>8.48</td>\n",
       "      <td>11.86</td>\n",
       "      <td>23.74</td>\n",
       "      <td>-53.88</td>\n",
       "      <td>-67.39</td>\n",
       "      <td>-18.98</td>\n",
       "      <td>-57.61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.896302</td>\n",
       "      <td>0.289649</td>\n",
       "      <td>-7.334934</td>\n",
       "      <td>198.14</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>19.58</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>148.77</td>\n",
       "      <td>0.950721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.95</td>\n",
       "      <td>5.27</td>\n",
       "      <td>325.47</td>\n",
       "      <td>2.65</td>\n",
       "      <td>11.96</td>\n",
       "      <td>37.07</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.896302</td>\n",
       "      <td>0.155866</td>\n",
       "      <td>3.630886</td>\n",
       "      <td>-233.86</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-206.21</td>\n",
       "      <td>2.905378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.10</td>\n",
       "      <td>5.66</td>\n",
       "      <td>297.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.85</td>\n",
       "      <td>36.26</td>\n",
       "      <td>-9.51</td>\n",
       "      <td>-13.49</td>\n",
       "      <td>-4.48</td>\n",
       "      <td>-7.61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-0.896302</td>\n",
       "      <td>0.171743</td>\n",
       "      <td>-18.504432</td>\n",
       "      <td>-27.72</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-11.47</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>-33.02</td>\n",
       "      <td>-35.835295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.56</td>\n",
       "      <td>3.24</td>\n",
       "      <td>50.12</td>\n",
       "      <td>56.44</td>\n",
       "      <td>-59.33</td>\n",
       "      <td>6.84</td>\n",
       "      <td>-53.39</td>\n",
       "      <td>-66.77</td>\n",
       "      <td>-27.10</td>\n",
       "      <td>-138.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-0.861568</td>\n",
       "      <td>0.952132</td>\n",
       "      <td>-6.782718</td>\n",
       "      <td>-79.98</td>\n",
       "      <td>-7.70</td>\n",
       "      <td>-57.55</td>\n",
       "      <td>-31.35</td>\n",
       "      <td>-72.53</td>\n",
       "      <td>-8.624891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3.69</td>\n",
       "      <td>7.07</td>\n",
       "      <td>159.68</td>\n",
       "      <td>16.90</td>\n",
       "      <td>30.06</td>\n",
       "      <td>29.86</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-28.57</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-27.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.096090</td>\n",
       "      <td>0.534729</td>\n",
       "      <td>-0.361713</td>\n",
       "      <td>44.91</td>\n",
       "      <td>21.73</td>\n",
       "      <td>21.37</td>\n",
       "      <td>8.50</td>\n",
       "      <td>25.50</td>\n",
       "      <td>4.805396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5.98</td>\n",
       "      <td>58.51</td>\n",
       "      <td>267.09</td>\n",
       "      <td>14.18</td>\n",
       "      <td>-49.19</td>\n",
       "      <td>-61.15</td>\n",
       "      <td>-171.19</td>\n",
       "      <td>-194.40</td>\n",
       "      <td>-26.00</td>\n",
       "      <td>-38.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-3.183320</td>\n",
       "      <td>0.197237</td>\n",
       "      <td>-18.565483</td>\n",
       "      <td>149.06</td>\n",
       "      <td>-44.72</td>\n",
       "      <td>-94.72</td>\n",
       "      <td>-9.98</td>\n",
       "      <td>149.43</td>\n",
       "      <td>-10.641540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2.52</td>\n",
       "      <td>58.51</td>\n",
       "      <td>14.61</td>\n",
       "      <td>57.72</td>\n",
       "      <td>-11.99</td>\n",
       "      <td>-5.22</td>\n",
       "      <td>-97.90</td>\n",
       "      <td>-1013.76</td>\n",
       "      <td>-25.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3.394696</td>\n",
       "      <td>1.696991</td>\n",
       "      <td>-41.181406</td>\n",
       "      <td>-1932.08</td>\n",
       "      <td>-15.02</td>\n",
       "      <td>-44.05</td>\n",
       "      <td>-14.14</td>\n",
       "      <td>-1667.67</td>\n",
       "      <td>22.597350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.50</td>\n",
       "      <td>2.74</td>\n",
       "      <td>347.91</td>\n",
       "      <td>10.33</td>\n",
       "      <td>37.06</td>\n",
       "      <td>25.27</td>\n",
       "      <td>-86.67</td>\n",
       "      <td>-143.92</td>\n",
       "      <td>-17.84</td>\n",
       "      <td>-52.74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-2.041814</td>\n",
       "      <td>0.380736</td>\n",
       "      <td>-10.717970</td>\n",
       "      <td>-117.41</td>\n",
       "      <td>25.27</td>\n",
       "      <td>68.05</td>\n",
       "      <td>23.15</td>\n",
       "      <td>-123.04</td>\n",
       "      <td>22.597350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7241 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    매출채권회전률  매입채무회전률    유동비율  차입금의존도  매출액증가율  매출액총이익률  매출액영업이익률  매출액순이익률  \\\n",
       "0     18.91    58.88  114.21   53.16   66.81     0.00    -14.46    -8.54   \n",
       "1      2.50     6.22  232.13    0.00  -20.58     3.74    -35.59  -102.58   \n",
       "2      2.71     7.41  306.73    8.48   11.86    23.74    -53.88   -67.39   \n",
       "3      1.95     5.27  325.47    2.65   11.96    37.07      1.96     0.75   \n",
       "4      2.10     5.66  297.75    0.00   18.85    36.26     -9.51   -13.49   \n",
       "..      ...      ...     ...     ...     ...      ...       ...      ...   \n",
       "59     1.56     3.24   50.12   56.44  -59.33     6.84    -53.39   -66.77   \n",
       "60     3.69     7.07  159.68   16.90   30.06    29.86     -0.98   -28.57   \n",
       "61     5.98    58.51  267.09   14.18  -49.19   -61.15   -171.19  -194.40   \n",
       "62     2.52    58.51   14.61   57.72  -11.99    -5.22    -97.90 -1013.76   \n",
       "63     1.50     2.74  347.91   10.33   37.06    25.27    -86.67  -143.92   \n",
       "\n",
       "    총자본영업이익률  자기자본순이익률  ...  총자본회전률      RETA      TLTA     이자보상배율  vol유동비율  \\\n",
       "0     -18.98    -29.43  ...    1.45 -0.139228  0.575696  -9.989503   -26.80   \n",
       "1     -12.93    -65.10  ...    0.36 -0.896302  0.296247 -14.082157   136.87   \n",
       "2     -18.98    -57.61  ...    0.48 -0.896302  0.289649  -7.334934   198.14   \n",
       "3       0.78      0.35  ...    0.40 -0.896302  0.155866   3.630886  -233.86   \n",
       "4      -4.48     -7.61  ...    0.47 -0.896302  0.171743 -18.504432   -27.72   \n",
       "..       ...       ...  ...     ...       ...       ...        ...      ...   \n",
       "59    -27.10   -138.28  ...    0.51 -0.861568  0.952132  -6.782718   -79.98   \n",
       "60     -0.50    -27.95  ...    0.51  0.096090  0.534729  -0.361713    44.91   \n",
       "61    -26.00    -38.66  ...    0.15 -3.183320  0.197237 -18.565483   149.06   \n",
       "62    -25.89      0.00  ...    0.26 -3.394696  1.696991 -41.181406 -1932.08   \n",
       "63    -17.84    -52.74  ...    0.21 -2.041814  0.380736 -10.717970  -117.41   \n",
       "\n",
       "    vol매출액총이익률  vol매출액영업이익률  vol총자본영업이익률  vol당좌비율  vol이자보상배율  \n",
       "0       -14.35       -16.32       -16.39    -3.29 -11.021527  \n",
       "1        13.35        12.07        14.13   143.03  -0.677342  \n",
       "2        -0.59        19.58        -1.60   148.77   0.950721  \n",
       "3        -1.39        -2.09        -0.68  -206.21   2.905378  \n",
       "4        -0.81       -11.47        -5.26   -33.02 -35.835295  \n",
       "..         ...          ...          ...      ...        ...  \n",
       "59       -7.70       -57.55       -31.35   -72.53  -8.624891  \n",
       "60       21.73        21.37         8.50    25.50   4.805396  \n",
       "61      -44.72       -94.72        -9.98   149.43 -10.641540  \n",
       "62      -15.02       -44.05       -14.14 -1667.67  22.597350  \n",
       "63       25.27        68.05        23.15  -123.04  22.597350  \n",
       "\n",
       "[7241 rows x 22 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expansion_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 확장기 Scaling 및 oversampling(SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_normal = pd.read_csv('../Data/WIN/transition_normal_win.csv',encoding='cp949')\n",
    "transition_default = pd.read_csv('../Data/WIN/transition_default_win.csv',encoding='cp949')\n",
    "transition = pd.concat([transition_normal,transition_default],axis=0)\n",
    "\n",
    "transition_00 = transition[transition['회계년도']==2000]\n",
    "transition_01 = transition[transition['회계년도']==2001]\n",
    "transition_05 = transition[transition['회계년도']==2005]\n",
    "transition_11 = transition[transition['회계년도']==2011]\n",
    "transition_13 = transition[transition['회계년도']==2013]\n",
    "transition_17 = transition[transition['회계년도']==2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_transition_00 = transition_00['부도']\n",
    "y_transition_01 = transition_01['부도']\n",
    "y_transition_05 = transition_05['부도']\n",
    "y_transition_11 = transition_11['부도']\n",
    "y_transition_13 = transition_13['부도']\n",
    "y_transition_17 = transition_17['부도']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RETA</th>\n",
       "      <th>매출액영업이익률</th>\n",
       "      <th>총자본영업이익률</th>\n",
       "      <th>매출액순이익률</th>\n",
       "      <th>이자보상배율</th>\n",
       "      <th>vol매출액영업이익률</th>\n",
       "      <th>vol매출액총이익률</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.139228</td>\n",
       "      <td>-14.46</td>\n",
       "      <td>-18.98</td>\n",
       "      <td>-8.54</td>\n",
       "      <td>-9.989503</td>\n",
       "      <td>-16.32</td>\n",
       "      <td>-14.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.896302</td>\n",
       "      <td>-35.59</td>\n",
       "      <td>-12.93</td>\n",
       "      <td>-102.58</td>\n",
       "      <td>-14.082157</td>\n",
       "      <td>12.07</td>\n",
       "      <td>13.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.896302</td>\n",
       "      <td>-53.88</td>\n",
       "      <td>-18.98</td>\n",
       "      <td>-67.39</td>\n",
       "      <td>-7.334934</td>\n",
       "      <td>19.58</td>\n",
       "      <td>-0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.896302</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.630886</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.896302</td>\n",
       "      <td>-9.51</td>\n",
       "      <td>-4.48</td>\n",
       "      <td>-13.49</td>\n",
       "      <td>-18.504432</td>\n",
       "      <td>-11.47</td>\n",
       "      <td>-0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-0.861568</td>\n",
       "      <td>-53.39</td>\n",
       "      <td>-27.10</td>\n",
       "      <td>-66.77</td>\n",
       "      <td>-6.782718</td>\n",
       "      <td>-57.55</td>\n",
       "      <td>-7.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.096090</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-28.57</td>\n",
       "      <td>-0.361713</td>\n",
       "      <td>21.37</td>\n",
       "      <td>21.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-3.183320</td>\n",
       "      <td>-171.19</td>\n",
       "      <td>-26.00</td>\n",
       "      <td>-194.40</td>\n",
       "      <td>-18.565483</td>\n",
       "      <td>-94.72</td>\n",
       "      <td>-44.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-3.394696</td>\n",
       "      <td>-97.90</td>\n",
       "      <td>-25.89</td>\n",
       "      <td>-1013.76</td>\n",
       "      <td>-41.181406</td>\n",
       "      <td>-44.05</td>\n",
       "      <td>-15.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-2.041814</td>\n",
       "      <td>-86.67</td>\n",
       "      <td>-17.84</td>\n",
       "      <td>-143.92</td>\n",
       "      <td>-10.717970</td>\n",
       "      <td>68.05</td>\n",
       "      <td>25.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7241 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RETA  매출액영업이익률  총자본영업이익률  매출액순이익률     이자보상배율  vol매출액영업이익률  vol매출액총이익률\n",
       "0  -0.139228    -14.46    -18.98    -8.54  -9.989503       -16.32      -14.35\n",
       "1  -0.896302    -35.59    -12.93  -102.58 -14.082157        12.07       13.35\n",
       "2  -0.896302    -53.88    -18.98   -67.39  -7.334934        19.58       -0.59\n",
       "3  -0.896302      1.96      0.78     0.75   3.630886        -2.09       -1.39\n",
       "4  -0.896302     -9.51     -4.48   -13.49 -18.504432       -11.47       -0.81\n",
       "..       ...       ...       ...      ...        ...          ...         ...\n",
       "59 -0.861568    -53.39    -27.10   -66.77  -6.782718       -57.55       -7.70\n",
       "60  0.096090     -0.98     -0.50   -28.57  -0.361713        21.37       21.73\n",
       "61 -3.183320   -171.19    -26.00  -194.40 -18.565483       -94.72      -44.72\n",
       "62 -3.394696    -97.90    -25.89 -1013.76 -41.181406       -44.05      -15.02\n",
       "63 -2.041814    -86.67    -17.84  -143.92 -10.717970        68.05       25.27\n",
       "\n",
       "[7241 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expansion_final_lst=['RETA','매출액영업이익률','총자본영업이익률','매출액순이익률','이자보상배율','vol매출액영업이익률','vol매출액총이익률']\n",
    "expansion_tf = expansion[expansion_final_lst]\n",
    "expansion_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>거래소코드</th>\n",
       "      <th>회계년도</th>\n",
       "      <th>매출채권회전률</th>\n",
       "      <th>매입채무회전률</th>\n",
       "      <th>유동비율</th>\n",
       "      <th>차입금의존도</th>\n",
       "      <th>매출액증가율</th>\n",
       "      <th>매출액총이익률</th>\n",
       "      <th>매출액영업이익률</th>\n",
       "      <th>...</th>\n",
       "      <th>RETA</th>\n",
       "      <th>TLTA</th>\n",
       "      <th>이자보상배율</th>\n",
       "      <th>vol유동비율</th>\n",
       "      <th>vol매출액총이익률</th>\n",
       "      <th>vol매출액영업이익률</th>\n",
       "      <th>vol총자본영업이익률</th>\n",
       "      <th>vol당좌비율</th>\n",
       "      <th>vol이자보상배율</th>\n",
       "      <th>부도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2002</td>\n",
       "      <td>18.91</td>\n",
       "      <td>58.88</td>\n",
       "      <td>114.21</td>\n",
       "      <td>53.16</td>\n",
       "      <td>66.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-14.46</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139228</td>\n",
       "      <td>0.575696</td>\n",
       "      <td>-9.989503</td>\n",
       "      <td>-26.80</td>\n",
       "      <td>-14.35</td>\n",
       "      <td>-16.32</td>\n",
       "      <td>-16.39</td>\n",
       "      <td>-3.29</td>\n",
       "      <td>-11.021527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2006</td>\n",
       "      <td>2.50</td>\n",
       "      <td>6.22</td>\n",
       "      <td>232.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-20.58</td>\n",
       "      <td>3.74</td>\n",
       "      <td>-35.59</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.896302</td>\n",
       "      <td>0.296247</td>\n",
       "      <td>-14.082157</td>\n",
       "      <td>136.87</td>\n",
       "      <td>13.35</td>\n",
       "      <td>12.07</td>\n",
       "      <td>14.13</td>\n",
       "      <td>143.03</td>\n",
       "      <td>-0.677342</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2010</td>\n",
       "      <td>2.71</td>\n",
       "      <td>7.41</td>\n",
       "      <td>306.73</td>\n",
       "      <td>8.48</td>\n",
       "      <td>11.86</td>\n",
       "      <td>23.74</td>\n",
       "      <td>-53.88</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.896302</td>\n",
       "      <td>0.289649</td>\n",
       "      <td>-7.334934</td>\n",
       "      <td>198.14</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>19.58</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>148.77</td>\n",
       "      <td>0.950721</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.95</td>\n",
       "      <td>5.27</td>\n",
       "      <td>325.47</td>\n",
       "      <td>2.65</td>\n",
       "      <td>11.96</td>\n",
       "      <td>37.07</td>\n",
       "      <td>1.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.896302</td>\n",
       "      <td>0.155866</td>\n",
       "      <td>3.630886</td>\n",
       "      <td>-233.86</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-206.21</td>\n",
       "      <td>2.905378</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.66</td>\n",
       "      <td>297.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.85</td>\n",
       "      <td>36.26</td>\n",
       "      <td>-9.51</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.896302</td>\n",
       "      <td>0.171743</td>\n",
       "      <td>-18.504432</td>\n",
       "      <td>-27.72</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-11.47</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>-33.02</td>\n",
       "      <td>-35.835295</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>잘만테크(주)</td>\n",
       "      <td>90120</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.56</td>\n",
       "      <td>3.24</td>\n",
       "      <td>50.12</td>\n",
       "      <td>56.44</td>\n",
       "      <td>-59.33</td>\n",
       "      <td>6.84</td>\n",
       "      <td>-53.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.861568</td>\n",
       "      <td>0.952132</td>\n",
       "      <td>-6.782718</td>\n",
       "      <td>-79.98</td>\n",
       "      <td>-7.70</td>\n",
       "      <td>-57.55</td>\n",
       "      <td>-31.35</td>\n",
       "      <td>-72.53</td>\n",
       "      <td>-8.624891</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>제이앤유글로벌</td>\n",
       "      <td>86200</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.69</td>\n",
       "      <td>7.07</td>\n",
       "      <td>159.68</td>\n",
       "      <td>16.90</td>\n",
       "      <td>30.06</td>\n",
       "      <td>29.86</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096090</td>\n",
       "      <td>0.534729</td>\n",
       "      <td>-0.361713</td>\n",
       "      <td>44.91</td>\n",
       "      <td>21.73</td>\n",
       "      <td>21.37</td>\n",
       "      <td>8.50</td>\n",
       "      <td>25.50</td>\n",
       "      <td>4.805396</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>평안물산(주)</td>\n",
       "      <td>37240</td>\n",
       "      <td>2010</td>\n",
       "      <td>5.98</td>\n",
       "      <td>58.51</td>\n",
       "      <td>267.09</td>\n",
       "      <td>14.18</td>\n",
       "      <td>-49.19</td>\n",
       "      <td>-61.15</td>\n",
       "      <td>-171.19</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.183320</td>\n",
       "      <td>0.197237</td>\n",
       "      <td>-18.565483</td>\n",
       "      <td>149.06</td>\n",
       "      <td>-44.72</td>\n",
       "      <td>-94.72</td>\n",
       "      <td>-9.98</td>\n",
       "      <td>149.43</td>\n",
       "      <td>-10.641540</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>퓨쳐비젼(주)</td>\n",
       "      <td>42570</td>\n",
       "      <td>2007</td>\n",
       "      <td>2.52</td>\n",
       "      <td>58.51</td>\n",
       "      <td>14.61</td>\n",
       "      <td>57.72</td>\n",
       "      <td>-11.99</td>\n",
       "      <td>-5.22</td>\n",
       "      <td>-97.90</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.394696</td>\n",
       "      <td>1.696991</td>\n",
       "      <td>-41.181406</td>\n",
       "      <td>-1932.08</td>\n",
       "      <td>-15.02</td>\n",
       "      <td>-44.05</td>\n",
       "      <td>-14.14</td>\n",
       "      <td>-1667.67</td>\n",
       "      <td>22.597350</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>한국통신데이타(주)</td>\n",
       "      <td>45760</td>\n",
       "      <td>2007</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.74</td>\n",
       "      <td>347.91</td>\n",
       "      <td>10.33</td>\n",
       "      <td>37.06</td>\n",
       "      <td>25.27</td>\n",
       "      <td>-86.67</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.041814</td>\n",
       "      <td>0.380736</td>\n",
       "      <td>-10.717970</td>\n",
       "      <td>-117.41</td>\n",
       "      <td>25.27</td>\n",
       "      <td>68.05</td>\n",
       "      <td>23.15</td>\n",
       "      <td>-123.04</td>\n",
       "      <td>22.597350</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7241 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           회사명  거래소코드  회계년도  매출채권회전률  매입채무회전률    유동비율  차입금의존도  매출액증가율  \\\n",
       "0     (주)CMG제약  58820  2002    18.91    58.88  114.21   53.16   66.81   \n",
       "1     (주)CMG제약  58820  2006     2.50     6.22  232.13    0.00  -20.58   \n",
       "2     (주)CMG제약  58820  2010     2.71     7.41  306.73    8.48   11.86   \n",
       "3     (주)CMG제약  58820  2014     1.95     5.27  325.47    2.65   11.96   \n",
       "4     (주)CMG제약  58820  2015     2.10     5.66  297.75    0.00   18.85   \n",
       "..         ...    ...   ...      ...      ...     ...     ...     ...   \n",
       "59     잘만테크(주)  90120  2014     1.56     3.24   50.12   56.44  -59.33   \n",
       "60     제이앤유글로벌  86200  2015     3.69     7.07  159.68   16.90   30.06   \n",
       "61     평안물산(주)  37240  2010     5.98    58.51  267.09   14.18  -49.19   \n",
       "62     퓨쳐비젼(주)  42570  2007     2.52    58.51   14.61   57.72  -11.99   \n",
       "63  한국통신데이타(주)  45760  2007     1.50     2.74  347.91   10.33   37.06   \n",
       "\n",
       "    매출액총이익률  매출액영업이익률  ...      RETA      TLTA     이자보상배율  vol유동비율  \\\n",
       "0      0.00    -14.46  ... -0.139228  0.575696  -9.989503   -26.80   \n",
       "1      3.74    -35.59  ... -0.896302  0.296247 -14.082157   136.87   \n",
       "2     23.74    -53.88  ... -0.896302  0.289649  -7.334934   198.14   \n",
       "3     37.07      1.96  ... -0.896302  0.155866   3.630886  -233.86   \n",
       "4     36.26     -9.51  ... -0.896302  0.171743 -18.504432   -27.72   \n",
       "..      ...       ...  ...       ...       ...        ...      ...   \n",
       "59     6.84    -53.39  ... -0.861568  0.952132  -6.782718   -79.98   \n",
       "60    29.86     -0.98  ...  0.096090  0.534729  -0.361713    44.91   \n",
       "61   -61.15   -171.19  ... -3.183320  0.197237 -18.565483   149.06   \n",
       "62    -5.22    -97.90  ... -3.394696  1.696991 -41.181406 -1932.08   \n",
       "63    25.27    -86.67  ... -2.041814  0.380736 -10.717970  -117.41   \n",
       "\n",
       "    vol매출액총이익률  vol매출액영업이익률  vol총자본영업이익률  vol당좌비율  vol이자보상배율   부도  \n",
       "0       -14.35       -16.32       -16.39    -3.29 -11.021527  0.0  \n",
       "1        13.35        12.07        14.13   143.03  -0.677342  0.0  \n",
       "2        -0.59        19.58        -1.60   148.77   0.950721  0.0  \n",
       "3        -1.39        -2.09        -0.68  -206.21   2.905378  0.0  \n",
       "4        -0.81       -11.47        -5.26   -33.02 -35.835295  0.0  \n",
       "..         ...          ...          ...      ...        ...  ...  \n",
       "59       -7.70       -57.55       -31.35   -72.53  -8.624891  1.0  \n",
       "60       21.73        21.37         8.50    25.50   4.805396  1.0  \n",
       "61      -44.72       -94.72        -9.98   149.43 -10.641540  1.0  \n",
       "62      -15.02       -44.05       -14.14 -1667.67  22.597350  1.0  \n",
       "63       25.27        68.05        23.15  -123.04  22.597350  1.0  \n",
       "\n",
       "[7241 rows x 26 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "expansion_x_tf = expansion[expansion_final_lst]\n",
    "expansion_y_tf = expansion['부도']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transition_00_tf\n",
    "transition_01_tf\n",
    "transition_05_tf\n",
    "transition_11_tf\n",
    "transition_13_tf = scaler_std.transform(transition_13)\n",
    " \n",
    "transition_17_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[transition_00,transition_01,transition_05,transition_11,transition_13,transition_17]\n",
    "for i in range(len(A)):\n",
    "    A[i] = A[i][expansion_final_lst]\n",
    "    A[i] = A[i].reset_index(drop=True)\n",
    "\n",
    "X_transition_00=A[0]\n",
    "X_transition_01=A[1]\n",
    "X_transition_05=A[2]\n",
    "X_transition_11=A[3]\n",
    "X_transition_13=A[4]\n",
    "X_transition_17=A[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_transition_00\n",
    "y_transition_00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,RAW_X_test,y_train,RAW_y_test = train_test_split(expansion_x_tf,expansion_y_tf,test_size = 0.3, stratify = expansion_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RETA', '매출액영업이익률', '총자본영업이익률', '매출액순이익률', '이자보상배율', 'vol매출액영업이익률',\n",
       "       'vol매출액총이익률'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transition_00.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RETA', '매출액영업이익률', '총자본영업이익률', '매출액순이익률', '이자보상배율', 'vol매출액영업이익률',\n",
       "       'vol매출액총이익률'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expansion_x_tf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (7534, 7)\n",
      "After OverSampling, the shape of train_y: (7534,) \n",
      "\n",
      "StandardScaler - SMOTE 적용 후 값의 분포 :\n",
      " 0.0    5023\n",
      "1.0    2511\n",
      "Name: 부도, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "scaler_std = StandardScaler()\n",
    "sm = SMOTE(sampling_strategy={1:int(y_train.value_counts().iloc[0]/2),0:y_train.value_counts().iloc[0]},random_state=1024)\n",
    "\n",
    "X_train_std = scaler_std.fit_transform(X_train)\n",
    "X_train_std = pd.DataFrame(X_train_std)\n",
    "X_resampled_std, y_resampled_std = sm.fit_resample(X_train_std,y_train)\n",
    "X_resampled_std.columns = expansion_x_tf.columns\n",
    "\n",
    "X_test_std = scaler_std.transform(RAW_X_test)\n",
    "X_test_std=pd.DataFrame(X_test_std)\n",
    "X_test_std.columns = expansion_x_tf.columns\n",
    "\n",
    "X_transition_00 = scaler_std.transform(X_transition_00)\n",
    "X_transition_00 = pd.DataFrame(X_transition_00)\n",
    "X_transition_00.columns = expansion_x_tf.columns\n",
    "\n",
    "X_transition_01 = scaler_std.transform(X_transition_01)\n",
    "X_transition_01 = pd.DataFrame(X_transition_01)\n",
    "X_transition_01.columns = expansion_x_tf.columns\n",
    "\n",
    "X_transition_05 = scaler_std.transform(X_transition_05)\n",
    "X_transition_05 = pd.DataFrame(X_transition_05)\n",
    "X_transition_05.columns = expansion_x_tf.columns\n",
    "\n",
    "X_transition_11 = scaler_std.transform(X_transition_11)\n",
    "X_transition_11 = pd.DataFrame(X_transition_11)\n",
    "X_transition_11.columns = expansion_x_tf.columns\n",
    "\n",
    "X_transition_13 = scaler_std.transform(X_transition_13)\n",
    "X_transition_13 = pd.DataFrame(X_transition_13)\n",
    "X_transition_13.columns = expansion_x_tf.columns\n",
    "\n",
    "X_transition_17 = scaler_std.transform(X_transition_17)\n",
    "X_transition_17 = pd.DataFrame(X_transition_17)\n",
    "X_transition_17.columns = expansion_x_tf.columns\n",
    "\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_resampled_std.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_resampled_std.shape))\n",
    "print('StandardScaler - SMOTE 적용 후 값의 분포 :\\n',y_resampled_std.value_counts())\n",
    "\n",
    "RAW_y_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_std = pd.concat([X_test_std,RAW_y_test],axis=1)\n",
    "# test_std.to_csv('../Data/WIN_UP/recession_win_std_test.csv',index=False,encoding='cp949')\n",
    "\n",
    "# upsample_std = pd.concat([X_resampled_std,y_resampled_std],axis=1)\n",
    "# upsample_std.to_csv('../Data/WIN_UP/recession_win_std_smote.csv',index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7f31152cbd4166b782894b9ebeeec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:57:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "모델명: XGBClassifier\n",
      "학습 데이터 최적 파라미터\n",
      ": {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "학습 데이터 최고 정확도\n",
      ": 0.997\n",
      "     Negative(0)  Positive(1)  y_pred\n",
      "0       0.999998     0.000002     0.0\n",
      "1       0.998670     0.001330     0.0\n",
      "2       0.998249     0.001751     0.0\n",
      "3       0.999868     0.000132     0.0\n",
      "4       0.999998     0.000002     0.0\n",
      "..           ...          ...     ...\n",
      "673     0.999999     0.000001     0.0\n",
      "674     0.999690     0.000310     0.0\n",
      "675     0.999991     0.000009     0.0\n",
      "676     0.000012     0.999988     1.0\n",
      "677     0.999934     0.000066     0.0\n",
      "\n",
      "[678 rows x 3 columns]\n",
      "단일 모델 results :      thresholds         models  Accuracy  Precision  Recall  F1 score  \\\n",
      "0.1         0.1  XGBClassifier     0.985   0.050000     0.5  0.090909   \n",
      "0.2         0.2  XGBClassifier     0.985   0.058824     0.5  0.105263   \n",
      "0.3         0.3  XGBClassifier     0.985   0.076923     0.5  0.133333   \n",
      "0.4         0.4  XGBClassifier     0.985   0.100000     0.5  0.166667   \n",
      "0.5         0.5  XGBClassifier     0.985   0.100000     0.5  0.166667   \n",
      "0.6         0.6  XGBClassifier     0.985   0.100000     0.5  0.166667   \n",
      "0.7         0.7  XGBClassifier     0.985   0.142857     0.5  0.222222   \n",
      "0.8         0.8  XGBClassifier     0.985   0.250000     0.5  0.333333   \n",
      "0.9         0.9  XGBClassifier     0.985   0.250000     0.5  0.333333   \n",
      "\n",
      "     Auc_Score  \n",
      "0.1   0.881657  \n",
      "0.2   0.881657  \n",
      "0.3   0.881657  \n",
      "0.4   0.881657  \n",
      "0.5   0.881657  \n",
      "0.6   0.881657  \n",
      "0.7   0.881657  \n",
      "0.8   0.881657  \n",
      "0.9   0.881657  \n",
      "     thresholds         models  Accuracy  Precision  Recall  F1 score  \\\n",
      "0.1         0.1  XGBClassifier     0.985   0.050000     0.5  0.090909   \n",
      "0.2         0.2  XGBClassifier     0.985   0.058824     0.5  0.105263   \n",
      "0.3         0.3  XGBClassifier     0.985   0.076923     0.5  0.133333   \n",
      "0.4         0.4  XGBClassifier     0.985   0.100000     0.5  0.166667   \n",
      "0.5         0.5  XGBClassifier     0.985   0.100000     0.5  0.166667   \n",
      "0.6         0.6  XGBClassifier     0.985   0.100000     0.5  0.166667   \n",
      "0.7         0.7  XGBClassifier     0.985   0.142857     0.5  0.222222   \n",
      "0.8         0.8  XGBClassifier     0.985   0.250000     0.5  0.333333   \n",
      "0.9         0.9  XGBClassifier     0.985   0.250000     0.5  0.333333   \n",
      "\n",
      "     Auc_Score  \n",
      "0.1   0.881657  \n",
      "0.2   0.881657  \n",
      "0.3   0.881657  \n",
      "0.4   0.881657  \n",
      "0.5   0.881657  \n",
      "0.6   0.881657  \n",
      "0.7   0.881657  \n",
      "0.8   0.881657  \n",
      "0.9   0.881657  \n",
      "모델명: RandomForestClassifier\n",
      "학습 데이터 최적 파라미터\n",
      ": {'max_depth': 7, 'min_samples_split': 5}\n",
      "학습 데이터 최고 정확도\n",
      ": 0.985\n",
      "     Negative(0)  Positive(1)  y_pred\n",
      "0       1.000000     0.000000     0.0\n",
      "1       0.871590     0.128410     0.0\n",
      "2       0.984197     0.015803     0.0\n",
      "3       0.979388     0.020612     0.0\n",
      "4       1.000000     0.000000     0.0\n",
      "..           ...          ...     ...\n",
      "673     1.000000     0.000000     0.0\n",
      "674     0.979317     0.020683     0.0\n",
      "675     0.985104     0.014896     0.0\n",
      "676     0.000000     1.000000     1.0\n",
      "677     0.433855     0.566145     1.0\n",
      "\n",
      "[678 rows x 3 columns]\n",
      "단일 모델 results :      thresholds                  models  Accuracy  Precision  Recall  \\\n",
      "0.1         0.1  RandomForestClassifier     0.994   0.023810     1.0   \n",
      "0.2         0.2  RandomForestClassifier     0.994   0.054054     1.0   \n",
      "0.3         0.3  RandomForestClassifier     0.994   0.105263     1.0   \n",
      "0.4         0.4  RandomForestClassifier     0.994   0.200000     1.0   \n",
      "0.5         0.5  RandomForestClassifier     0.994   0.333333     1.0   \n",
      "0.6         0.6  RandomForestClassifier     0.994   0.200000     0.5   \n",
      "0.7         0.7  RandomForestClassifier     0.994   0.333333     0.5   \n",
      "0.8         0.8  RandomForestClassifier     0.994   1.000000     0.5   \n",
      "0.9         0.9  RandomForestClassifier     0.994   1.000000     0.5   \n",
      "\n",
      "     F1 score  Auc_Score  \n",
      "0.1  0.046512   0.997041  \n",
      "0.2  0.102564   0.997041  \n",
      "0.3  0.190476   0.997041  \n",
      "0.4  0.333333   0.997041  \n",
      "0.5  0.500000   0.997041  \n",
      "0.6  0.285714   0.997041  \n",
      "0.7  0.400000   0.997041  \n",
      "0.8  0.666667   0.997041  \n",
      "0.9  0.666667   0.997041  \n",
      "     thresholds                  models  Accuracy  Precision  Recall  \\\n",
      "0.1         0.1  RandomForestClassifier     0.994   0.023810     1.0   \n",
      "0.2         0.2  RandomForestClassifier     0.994   0.054054     1.0   \n",
      "0.3         0.3  RandomForestClassifier     0.994   0.105263     1.0   \n",
      "0.4         0.4  RandomForestClassifier     0.994   0.200000     1.0   \n",
      "0.5         0.5  RandomForestClassifier     0.994   0.333333     1.0   \n",
      "0.6         0.6  RandomForestClassifier     0.994   0.200000     0.5   \n",
      "0.7         0.7  RandomForestClassifier     0.994   0.333333     0.5   \n",
      "0.8         0.8  RandomForestClassifier     0.994   1.000000     0.5   \n",
      "0.9         0.9  RandomForestClassifier     0.994   1.000000     0.5   \n",
      "\n",
      "     F1 score  Auc_Score  \n",
      "0.1  0.046512   0.997041  \n",
      "0.2  0.102564   0.997041  \n",
      "0.3  0.190476   0.997041  \n",
      "0.4  0.333333   0.997041  \n",
      "0.5  0.500000   0.997041  \n",
      "0.6  0.285714   0.997041  \n",
      "0.7  0.400000   0.997041  \n",
      "0.8  0.666667   0.997041  \n",
      "0.9  0.666667   0.997041  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Auc_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.881657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.997041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     thresholds                  models  Accuracy  Precision  Recall  \\\n",
       "0.8         0.8           XGBClassifier     0.985       0.25     0.5   \n",
       "0.8         0.8  RandomForestClassifier     0.994       1.00     0.5   \n",
       "\n",
       "     F1 score  Auc_Score  \n",
       "0.8  0.333333   0.881657  \n",
       "0.8  0.666667   0.997041  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, accuracy_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression,  LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# df = pd.DataFrame(columns =['models','Accuracy','Precision', 'Recall', 'F1 score','Auc_Score'])\n",
    "\n",
    "\n",
    "\n",
    "class Model_Optimization():\n",
    "\n",
    "      def __init__(self):\n",
    "            \n",
    "            global model_df\n",
    "            model_df = pd.DataFrame(columns =['thresholds','models','Accuracy','Precision', 'Recall', 'F1 score','Auc_Score']) \n",
    "\n",
    "\n",
    "      #최적 파라미터 찾는 함수 ()\n",
    "      def grid(self,model_name, X_train=X_resampled_std, y_train=y_resampled_std, X_test=X_transition_00,y_test=y_transition_00):\n",
    "            global model_df\n",
    "\n",
    "            self.model_name = model_name\n",
    "            self.X_test = X_test\n",
    "            self.y_test = y_test\n",
    "            self.X_train = X_train\n",
    "            self.y_train  = y_train\n",
    "\n",
    "            if model_name == \"DecisionTreeClassifier\":\n",
    "                  dt = DecisionTreeClassifier()\n",
    "                  parameters = [{\"max_depth\": [3,5,7], \"min_samples_split\":[3,5,7]}]\n",
    "                  \n",
    "            elif model_name == \"RandomForestClassifier\":\n",
    "                  dt = RandomForestClassifier()\n",
    "                  parameters = [{\"max_depth\": [3,5,7], \"min_samples_split\":[3,5,7]}]\n",
    "                  \n",
    "            elif model_name == \"LogisticRegression\":\n",
    "                  dt = LogisticRegression()\n",
    "                  parameters = {'penalty':['l2', 'l1'],\n",
    "                  'C':[0.01, 0.1, 1, 5, 10]}\n",
    "                  \n",
    "            elif model_name == \"Linear SVM\": \n",
    "                  dt = SVC(probability=True)\n",
    "                  parameters = [{'kernel':['linear'], 'C':[0.001, 0.01, 0.025, 0.1, 1, 10, 100]}]\n",
    "                  \n",
    "            elif model_name == \"RBF SVM\": \n",
    "                  dt = SVC(probability=True)\n",
    "                  parameters = [{'gamma':[0.001, 0.01, 0.1, 1, 10, 100],'kernel':['rbf'],'C':[0.001, 0.01, 0.025, 0.1, 1, 10, 100]}]\n",
    "\n",
    "            elif model_name == \"AdaBoostClassifier\":\n",
    "                  dt= AdaBoostClassifier(random_state=0)\n",
    "                  parameters={'n_estimators':[5]}\n",
    "                  \n",
    "            elif model_name == \"GradientBoostingClassifier\":\n",
    "                  dt=GradientBoostingClassifier(random_state=0)\n",
    "                  parameters = {\n",
    "                  'n_estimators' : [100, 500],\n",
    "                  'learning_rate' : [0.05, 0.1]\n",
    "                              }\n",
    "\n",
    "            elif model_name == \"XGBClassifier\":\n",
    "                  dt=XGBClassifier(random_state=0,verbose=1)\n",
    "                  parameters={'n_estimators':[100, 500], 'learning_rate':[0.05, 0.1], 'max_depth':[3,4]}\n",
    "                  \n",
    "            # elif model_name == \"LGBMClassifier\":\n",
    "            #       dt=LGBMClassifier(random_state=0)\n",
    "            #       parameters={'n_estimators':[400,800], 'learning_rate':[0.05, 0.1] , 'max_depth':[3,4]}\n",
    "            \n",
    "            elif model_name == \"KNeighborsClassifier\":\n",
    "                  dt = KNeighborsClassifier()\n",
    "                  parameters = {'n_neighbors':[3]}\n",
    "                  \n",
    "            elif model_name == 'MLPClassifier':\n",
    "                  dt = MLPClassifier(random_state=0)\n",
    "                  parameters={'max_iter':[1000], 'hidden_layer_sizes':[1], 'activation':['logistic'],\n",
    "                              'solver':['sgd'], 'alpha':[0.01], 'batch_size':[32],\n",
    "                              'learning_rate_init':[0.1], 'max_iter':[500]}\n",
    "                  \n",
    "            elif model_name == 'GaussianProcessClassifier':\n",
    "                  dt = GaussianProcessClassifier(random_state=0)\n",
    "                  parameters={'kernel': [1.0*RBF(1.0)]}\n",
    "                  \n",
    "            elif model_name == 'GaussianNB':\n",
    "                  dt = GaussianNB()\n",
    "                  parameters={}\n",
    "                  \n",
    "            elif model_name =='QuadraticDiscriminantAnalysis':\n",
    "                  #선형판별분석\n",
    "                  dt = QuadraticDiscriminantAnalysis()\n",
    "                  parameters={}\n",
    "                  \n",
    "            # 최적 파라미터 찾기 \n",
    "            self.grid_dt  = GridSearchCV(dt, param_grid = parameters, cv=5, refit =True, n_jobs=-1)\n",
    "            self.grid_dt.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            print(f\"모델명: {model_name}\")\n",
    "            print(f\"학습 데이터 최적 파라미터\\n: {self.grid_dt.best_params_}\")\n",
    "            print(f\"학습 데이터 최고 정확도\\n: {self.grid_dt.best_score_:.3f}\")\n",
    "\n",
    "            #지도학습 알고리즘 \n",
    "            estimator = self.grid_dt.best_estimator_\n",
    "            y_pred = pd.DataFrame(estimator.predict(self.X_test))\n",
    "            y_pred_probability = pd.DataFrame(estimator.predict_proba(self.X_test))\n",
    "            # print(f\"예측 정확도\\n: {accuracy_score(self.y_test, y_pred):.3f}\")\n",
    "\n",
    "            prediction = pd.concat([y_pred_probability, y_pred], axis = 1)\n",
    "\n",
    "            prediction.columns = [\"Negative(0)\", \"Positive(1)\", \"y_pred\"]\n",
    "\n",
    "            print(prediction)\n",
    "            self.pred_proba_1 = np.array(prediction[\"Positive(1)\"]).reshape(-1, 1)\n",
    "            self.accuracy= round(accuracy_score(self.y_test, y_pred),3)\n",
    "            self.FPRs, self.TPRs, self.thresholds = roc_curve(self.y_test, self.pred_proba_1)\n",
    "            \n",
    "            return estimator\n",
    "\n",
    "\n",
    "\n",
    "      # 단일 모델 임계치별 score 출력 하는 함수 *주의  self.thresholds 값 내부 리스트 수정해줘야함 \n",
    "      def get_thresholds_score(self):\n",
    "            global model_df\n",
    "\n",
    "            \n",
    "            self.thresholds = [0.1, 0.2 , 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "            #평가지표용 리스트생성\n",
    "            precisions = []\n",
    "            recalls = []\n",
    "            f1_scores = []\n",
    "            auc_scores=[]\n",
    "            threshold_ =[]\n",
    "            \n",
    "            \n",
    "            \n",
    "            for threshold in self.thresholds:\n",
    "                  binarizer = Binarizer(threshold= threshold)\n",
    "                  # print(threshold)\n",
    "                  # 임계점 지정하여 Binariazer() 객체 생성\n",
    "                  pred_proba = binarizer.fit_transform(self.pred_proba_1)\n",
    "                  # print(pred_proba)\n",
    "                  # 임계점을 기준으로 데이터 변환\n",
    "\n",
    "                  precision = precision_score(self.y_test, pred_proba)\n",
    "                  recall = recall_score(self.y_test, pred_proba)\n",
    "                  f1score = f1_score(self.y_test, pred_proba)\n",
    "                  auc_score=roc_auc_score(self.y_test, self.pred_proba_1)\n",
    "\n",
    "                  precisions.append(precision)\n",
    "                  recalls.append(recall)\n",
    "                  f1_scores.append(f1score)\n",
    "                  auc_scores.append(auc_score)\n",
    "                  threshold_.append(threshold)\n",
    "                  \n",
    "\n",
    "            results = pd.DataFrame(data = {\"thresholds\":threshold_, \"models\":self.model_name,\"Accuracy\":self.accuracy,\"Precision\": precisions,\n",
    "                                          \"Recall\": recalls,\n",
    "                                          \"F1 score\": f1_scores,\"Auc_Score\":auc_scores}, index = self.thresholds)                 \n",
    "\n",
    "            print(f'단일 모델 results : {results}')      \n",
    "            return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      #모든 모델 성능 비교 함수 \n",
    "      def get_model_socre(self,input_list):\n",
    "            global model_df \n",
    "\n",
    "            mod = Model_Optimization()\n",
    "            for i in tqdm(input_list):\n",
    "                  mod.grid(model_name=i)\n",
    "                  results_df = mod.get_thresholds_score()\n",
    "\n",
    "                  #평가지표 데이터 프레임화 \n",
    "                  print(results_df)\n",
    "                  #기준 평가지표로 정렬\n",
    "                  results_df.sort_values(\"F1 score\", ascending=False, inplace=True)\n",
    "                  new_model_df= results_df.iloc[:1]\n",
    "                  model_df = pd.concat([model_df,new_model_df])\n",
    "                  \n",
    "            return model_df\n",
    "        \n",
    "list = ['XGBClassifier','RandomForestClassifier']\n",
    "model = Model_Optimization()\n",
    "model.get_model_socre(list)\n",
    "model_df.to_csv('../Data/result/2000년_확장.csv',index=False, encoding='cp949')\n",
    "model_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6badb48aaa4014881621b188875582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:58:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "모델명: XGBClassifier\n",
      "학습 데이터 최적 파라미터\n",
      ": {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "학습 데이터 최고 정확도\n",
      ": 0.997\n",
      "     Negative(0)  Positive(1)  y_pred\n",
      "0       0.999945     0.000055     0.0\n",
      "1       0.999928     0.000072     0.0\n",
      "2       0.999998     0.000002     0.0\n",
      "3       0.998243     0.001757     0.0\n",
      "4       0.999932     0.000068     0.0\n",
      "..           ...          ...     ...\n",
      "841     0.999491     0.000509     0.0\n",
      "842     0.999996     0.000004     0.0\n",
      "843     0.997901     0.002099     0.0\n",
      "844     0.909254     0.090746     0.0\n",
      "845     0.999961     0.000039     0.0\n",
      "\n",
      "[846 rows x 3 columns]\n",
      "단일 모델 results :      thresholds         models  Accuracy  Precision    Recall  F1 score  \\\n",
      "0.1         0.1  XGBClassifier     0.968   0.021739  0.166667  0.038462   \n",
      "0.2         0.2  XGBClassifier     0.968   0.032258  0.166667  0.054054   \n",
      "0.3         0.3  XGBClassifier     0.968   0.038462  0.166667  0.062500   \n",
      "0.4         0.4  XGBClassifier     0.968   0.000000  0.000000  0.000000   \n",
      "0.5         0.5  XGBClassifier     0.968   0.000000  0.000000  0.000000   \n",
      "0.6         0.6  XGBClassifier     0.968   0.000000  0.000000  0.000000   \n",
      "0.7         0.7  XGBClassifier     0.968   0.000000  0.000000  0.000000   \n",
      "0.8         0.8  XGBClassifier     0.968   0.000000  0.000000  0.000000   \n",
      "0.9         0.9  XGBClassifier     0.968   0.000000  0.000000  0.000000   \n",
      "\n",
      "     Auc_Score  \n",
      "0.1   0.782738  \n",
      "0.2   0.782738  \n",
      "0.3   0.782738  \n",
      "0.4   0.782738  \n",
      "0.5   0.782738  \n",
      "0.6   0.782738  \n",
      "0.7   0.782738  \n",
      "0.8   0.782738  \n",
      "0.9   0.782738  \n",
      "     thresholds         models  Accuracy  Precision    Recall  F1 score  \\\n",
      "0.1         0.1  XGBClassifier     0.968   0.021739  0.166667  0.038462   \n",
      "0.2         0.2  XGBClassifier     0.968   0.032258  0.166667  0.054054   \n",
      "0.3         0.3  XGBClassifier     0.968   0.038462  0.166667  0.062500   \n",
      "0.4         0.4  XGBClassifier     0.968   0.000000  0.000000  0.000000   \n",
      "0.5         0.5  XGBClassifier     0.968   0.000000  0.000000  0.000000   \n",
      "0.6         0.6  XGBClassifier     0.968   0.000000  0.000000  0.000000   \n",
      "0.7         0.7  XGBClassifier     0.968   0.000000  0.000000  0.000000   \n",
      "0.8         0.8  XGBClassifier     0.968   0.000000  0.000000  0.000000   \n",
      "0.9         0.9  XGBClassifier     0.968   0.000000  0.000000  0.000000   \n",
      "\n",
      "     Auc_Score  \n",
      "0.1   0.782738  \n",
      "0.2   0.782738  \n",
      "0.3   0.782738  \n",
      "0.4   0.782738  \n",
      "0.5   0.782738  \n",
      "0.6   0.782738  \n",
      "0.7   0.782738  \n",
      "0.8   0.782738  \n",
      "0.9   0.782738  \n",
      "모델명: RandomForestClassifier\n",
      "학습 데이터 최적 파라미터\n",
      ": {'max_depth': 7, 'min_samples_split': 7}\n",
      "학습 데이터 최고 정확도\n",
      ": 0.985\n",
      "     Negative(0)  Positive(1)  y_pred\n",
      "0       0.957735     0.042265     0.0\n",
      "1       0.978800     0.021200     0.0\n",
      "2       1.000000     0.000000     0.0\n",
      "3       0.705461     0.294539     0.0\n",
      "4       0.919256     0.080744     0.0\n",
      "..           ...          ...     ...\n",
      "841     0.988826     0.011174     0.0\n",
      "842     1.000000     0.000000     0.0\n",
      "843     0.870486     0.129514     0.0\n",
      "844     0.862961     0.137039     0.0\n",
      "845     0.804146     0.195854     0.0\n",
      "\n",
      "[846 rows x 3 columns]\n",
      "단일 모델 results :      thresholds                  models  Accuracy  Precision    Recall  \\\n",
      "0.1         0.1  RandomForestClassifier     0.981   0.027027  0.666667   \n",
      "0.2         0.2  RandomForestClassifier     0.981   0.011494  0.166667   \n",
      "0.3         0.3  RandomForestClassifier     0.981   0.019608  0.166667   \n",
      "0.4         0.4  RandomForestClassifier     0.981   0.038462  0.166667   \n",
      "0.5         0.5  RandomForestClassifier     0.981   0.083333  0.166667   \n",
      "0.6         0.6  RandomForestClassifier     0.981   0.100000  0.166667   \n",
      "0.7         0.7  RandomForestClassifier     0.981   0.000000  0.000000   \n",
      "0.8         0.8  RandomForestClassifier     0.981   0.000000  0.000000   \n",
      "0.9         0.9  RandomForestClassifier     0.981   0.000000  0.000000   \n",
      "\n",
      "     F1 score  Auc_Score  \n",
      "0.1  0.051948   0.758135  \n",
      "0.2  0.021505   0.758135  \n",
      "0.3  0.035088   0.758135  \n",
      "0.4  0.062500   0.758135  \n",
      "0.5  0.111111   0.758135  \n",
      "0.6  0.125000   0.758135  \n",
      "0.7  0.000000   0.758135  \n",
      "0.8  0.000000   0.758135  \n",
      "0.9  0.000000   0.758135  \n",
      "     thresholds                  models  Accuracy  Precision    Recall  \\\n",
      "0.1         0.1  RandomForestClassifier     0.981   0.027027  0.666667   \n",
      "0.2         0.2  RandomForestClassifier     0.981   0.011494  0.166667   \n",
      "0.3         0.3  RandomForestClassifier     0.981   0.019608  0.166667   \n",
      "0.4         0.4  RandomForestClassifier     0.981   0.038462  0.166667   \n",
      "0.5         0.5  RandomForestClassifier     0.981   0.083333  0.166667   \n",
      "0.6         0.6  RandomForestClassifier     0.981   0.100000  0.166667   \n",
      "0.7         0.7  RandomForestClassifier     0.981   0.000000  0.000000   \n",
      "0.8         0.8  RandomForestClassifier     0.981   0.000000  0.000000   \n",
      "0.9         0.9  RandomForestClassifier     0.981   0.000000  0.000000   \n",
      "\n",
      "     F1 score  Auc_Score  \n",
      "0.1  0.051948   0.758135  \n",
      "0.2  0.021505   0.758135  \n",
      "0.3  0.035088   0.758135  \n",
      "0.4  0.062500   0.758135  \n",
      "0.5  0.111111   0.758135  \n",
      "0.6  0.125000   0.758135  \n",
      "0.7  0.000000   0.758135  \n",
      "0.8  0.000000   0.758135  \n",
      "0.9  0.000000   0.758135  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Auc_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.782738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.758135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     thresholds                  models  Accuracy  Precision    Recall  \\\n",
       "0.3         0.3           XGBClassifier     0.968   0.038462  0.166667   \n",
       "0.6         0.6  RandomForestClassifier     0.981   0.100000  0.166667   \n",
       "\n",
       "     F1 score  Auc_Score  \n",
       "0.3    0.0625   0.782738  \n",
       "0.6    0.1250   0.758135  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, accuracy_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression,  LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# df = pd.DataFrame(columns =['models','Accuracy','Precision', 'Recall', 'F1 score','Auc_Score'])\n",
    "\n",
    "\n",
    "\n",
    "class Model_Optimization():\n",
    "\n",
    "      def __init__(self):\n",
    "            \n",
    "            global model_df\n",
    "            model_df = pd.DataFrame(columns =['thresholds','models','Accuracy','Precision', 'Recall', 'F1 score','Auc_Score']) \n",
    "\n",
    "\n",
    "      #최적 파라미터 찾는 함수 ()\n",
    "      def grid(self,model_name, X_train=X_resampled_std, y_train=y_resampled_std, X_test=X_transition_01,y_test=y_transition_01):\n",
    "            global model_df\n",
    "\n",
    "            self.model_name = model_name\n",
    "            self.X_test = X_test\n",
    "            self.y_test = y_test\n",
    "            self.X_train = X_train\n",
    "            self.y_train  = y_train\n",
    "\n",
    "            if model_name == \"DecisionTreeClassifier\":\n",
    "                  dt = DecisionTreeClassifier()\n",
    "                  parameters = [{\"max_depth\": [3,5,7], \"min_samples_split\":[3,5,7]}]\n",
    "                  \n",
    "            elif model_name == \"RandomForestClassifier\":\n",
    "                  dt = RandomForestClassifier()\n",
    "                  parameters = [{\"max_depth\": [3,5,7], \"min_samples_split\":[3,5,7]}]\n",
    "                  \n",
    "            elif model_name == \"LogisticRegression\":\n",
    "                  dt = LogisticRegression()\n",
    "                  parameters = {'penalty':['l2', 'l1'],\n",
    "                  'C':[0.01, 0.1, 1, 5, 10]}\n",
    "                  \n",
    "            elif model_name == \"Linear SVM\": \n",
    "                  dt = SVC(probability=True)\n",
    "                  parameters = [{'kernel':['linear'], 'C':[0.001, 0.01, 0.025, 0.1, 1, 10, 100]}]\n",
    "                  \n",
    "            elif model_name == \"RBF SVM\": \n",
    "                  dt = SVC(probability=True)\n",
    "                  parameters = [{'gamma':[0.001, 0.01, 0.1, 1, 10, 100],'kernel':['rbf'],'C':[0.001, 0.01, 0.025, 0.1, 1, 10, 100]}]\n",
    "\n",
    "            elif model_name == \"AdaBoostClassifier\":\n",
    "                  dt= AdaBoostClassifier(random_state=0)\n",
    "                  parameters={'n_estimators':[5]}\n",
    "                  \n",
    "            elif model_name == \"GradientBoostingClassifier\":\n",
    "                  dt=GradientBoostingClassifier(random_state=0)\n",
    "                  parameters = {\n",
    "                  'n_estimators' : [100, 500],\n",
    "                  'learning_rate' : [0.05, 0.1]\n",
    "                              }\n",
    "\n",
    "            elif model_name == \"XGBClassifier\":\n",
    "                  dt=XGBClassifier(random_state=0,verbose=1)\n",
    "                  parameters={'n_estimators':[100, 500], 'learning_rate':[0.05, 0.1], 'max_depth':[3,4]}\n",
    "                  \n",
    "            # elif model_name == \"LGBMClassifier\":\n",
    "            #       dt=LGBMClassifier(random_state=0)\n",
    "            #       parameters={'n_estimators':[400,800], 'learning_rate':[0.05, 0.1] , 'max_depth':[3,4]}\n",
    "            \n",
    "            elif model_name == \"KNeighborsClassifier\":\n",
    "                  dt = KNeighborsClassifier()\n",
    "                  parameters = {'n_neighbors':[3]}\n",
    "                  \n",
    "            elif model_name == 'MLPClassifier':\n",
    "                  dt = MLPClassifier(random_state=0)\n",
    "                  parameters={'max_iter':[1000], 'hidden_layer_sizes':[1], 'activation':['logistic'],\n",
    "                              'solver':['sgd'], 'alpha':[0.01], 'batch_size':[32],\n",
    "                              'learning_rate_init':[0.1], 'max_iter':[500]}\n",
    "                  \n",
    "            elif model_name == 'GaussianProcessClassifier':\n",
    "                  dt = GaussianProcessClassifier(random_state=0)\n",
    "                  parameters={'kernel': [1.0*RBF(1.0)]}\n",
    "                  \n",
    "            elif model_name == 'GaussianNB':\n",
    "                  dt = GaussianNB()\n",
    "                  parameters={}\n",
    "                  \n",
    "            elif model_name =='QuadraticDiscriminantAnalysis':\n",
    "                  #선형판별분석\n",
    "                  dt = QuadraticDiscriminantAnalysis()\n",
    "                  parameters={}\n",
    "                  \n",
    "            # 최적 파라미터 찾기 \n",
    "            self.grid_dt  = GridSearchCV(dt, param_grid = parameters, cv=5, refit =True, n_jobs=-1)\n",
    "            self.grid_dt.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            print(f\"모델명: {model_name}\")\n",
    "            print(f\"학습 데이터 최적 파라미터\\n: {self.grid_dt.best_params_}\")\n",
    "            print(f\"학습 데이터 최고 정확도\\n: {self.grid_dt.best_score_:.3f}\")\n",
    "\n",
    "            #지도학습 알고리즘 \n",
    "            estimator = self.grid_dt.best_estimator_\n",
    "            y_pred = pd.DataFrame(estimator.predict(self.X_test))\n",
    "            y_pred_probability = pd.DataFrame(estimator.predict_proba(self.X_test))\n",
    "            # print(f\"예측 정확도\\n: {accuracy_score(self.y_test, y_pred):.3f}\")\n",
    "\n",
    "            prediction = pd.concat([y_pred_probability, y_pred], axis = 1)\n",
    "\n",
    "            prediction.columns = [\"Negative(0)\", \"Positive(1)\", \"y_pred\"]\n",
    "\n",
    "            print(prediction)\n",
    "            self.pred_proba_1 = np.array(prediction[\"Positive(1)\"]).reshape(-1, 1)\n",
    "            self.accuracy= round(accuracy_score(self.y_test, y_pred),3)\n",
    "            self.FPRs, self.TPRs, self.thresholds = roc_curve(self.y_test, self.pred_proba_1)\n",
    "            \n",
    "            return estimator\n",
    "\n",
    "\n",
    "\n",
    "      # 단일 모델 임계치별 score 출력 하는 함수 *주의  self.thresholds 값 내부 리스트 수정해줘야함 \n",
    "      def get_thresholds_score(self):\n",
    "            global model_df\n",
    "\n",
    "            \n",
    "            self.thresholds = [0.1, 0.2 , 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "            #평가지표용 리스트생성\n",
    "            precisions = []\n",
    "            recalls = []\n",
    "            f1_scores = []\n",
    "            auc_scores=[]\n",
    "            threshold_ =[]\n",
    "            \n",
    "            \n",
    "            \n",
    "            for threshold in self.thresholds:\n",
    "                  binarizer = Binarizer(threshold= threshold)\n",
    "                  # print(threshold)\n",
    "                  # 임계점 지정하여 Binariazer() 객체 생성\n",
    "                  pred_proba = binarizer.fit_transform(self.pred_proba_1)\n",
    "                  # print(pred_proba)\n",
    "                  # 임계점을 기준으로 데이터 변환\n",
    "\n",
    "                  precision = precision_score(self.y_test, pred_proba)\n",
    "                  recall = recall_score(self.y_test, pred_proba)\n",
    "                  f1score = f1_score(self.y_test, pred_proba)\n",
    "                  auc_score=roc_auc_score(self.y_test, self.pred_proba_1)\n",
    "\n",
    "                  precisions.append(precision)\n",
    "                  recalls.append(recall)\n",
    "                  f1_scores.append(f1score)\n",
    "                  auc_scores.append(auc_score)\n",
    "                  threshold_.append(threshold)\n",
    "                  \n",
    "\n",
    "            results = pd.DataFrame(data = {\"thresholds\":threshold_, \"models\":self.model_name,\"Accuracy\":self.accuracy,\"Precision\": precisions,\n",
    "                                          \"Recall\": recalls,\n",
    "                                          \"F1 score\": f1_scores,\"Auc_Score\":auc_scores}, index = self.thresholds)                 \n",
    "\n",
    "            print(f'단일 모델 results : {results}')      \n",
    "            return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      #모든 모델 성능 비교 함수 \n",
    "      def get_model_socre(self,input_list):\n",
    "            global model_df \n",
    "\n",
    "            mod = Model_Optimization()\n",
    "            for i in tqdm(input_list):\n",
    "                  mod.grid(model_name=i)\n",
    "                  results_df = mod.get_thresholds_score()\n",
    "\n",
    "                  #평가지표 데이터 프레임화 \n",
    "                  print(results_df)\n",
    "                  #기준 평가지표로 정렬\n",
    "                  results_df.sort_values(\"F1 score\", ascending=False, inplace=True)\n",
    "                  new_model_df= results_df.iloc[:1]\n",
    "                  model_df = pd.concat([model_df,new_model_df])\n",
    "                  \n",
    "            return model_df\n",
    "        \n",
    "list = ['XGBClassifier','RandomForestClassifier']\n",
    "model = Model_Optimization()\n",
    "model.get_model_socre(list)\n",
    "model_df.to_csv('../Data/result/2001년_확장.csv',index=False, encoding='cp949')\n",
    "\n",
    "model_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93b21c5f7af45d7b4d5daa6ca671d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:58:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "모델명: XGBClassifier\n",
      "학습 데이터 최적 파라미터\n",
      ": {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "학습 데이터 최고 정확도\n",
      ": 0.997\n",
      "     Negative(0)  Positive(1)  y_pred\n",
      "0       0.479603     0.520397     1.0\n",
      "1       0.986652     0.013347     0.0\n",
      "2       0.999998     0.000002     0.0\n",
      "3       0.999072     0.000927     0.0\n",
      "4       0.999906     0.000094     0.0\n",
      "..           ...          ...     ...\n",
      "976     0.999996     0.000004     0.0\n",
      "977     0.999999     0.000001     0.0\n",
      "978     0.999939     0.000061     0.0\n",
      "979     0.000002     0.999998     1.0\n",
      "980     0.974038     0.025962     0.0\n",
      "\n",
      "[981 rows x 3 columns]\n",
      "단일 모델 results :      thresholds         models  Accuracy  Precision  Recall  F1 score  \\\n",
      "0.1         0.1  XGBClassifier      0.94   0.009434     0.5  0.018519   \n",
      "0.2         0.2  XGBClassifier      0.94   0.011364     0.5  0.022222   \n",
      "0.3         0.3  XGBClassifier      0.94   0.012658     0.5  0.024691   \n",
      "0.4         0.4  XGBClassifier      0.94   0.014493     0.5  0.028169   \n",
      "0.5         0.5  XGBClassifier      0.94   0.016949     0.5  0.032787   \n",
      "0.6         0.6  XGBClassifier      0.94   0.020408     0.5  0.039216   \n",
      "0.7         0.7  XGBClassifier      0.94   0.024390     0.5  0.046512   \n",
      "0.8         0.8  XGBClassifier      0.94   0.025000     0.5  0.047619   \n",
      "0.9         0.9  XGBClassifier      0.94   0.030303     0.5  0.057143   \n",
      "\n",
      "     Auc_Score  \n",
      "0.1   0.929009  \n",
      "0.2   0.929009  \n",
      "0.3   0.929009  \n",
      "0.4   0.929009  \n",
      "0.5   0.929009  \n",
      "0.6   0.929009  \n",
      "0.7   0.929009  \n",
      "0.8   0.929009  \n",
      "0.9   0.929009  \n",
      "     thresholds         models  Accuracy  Precision  Recall  F1 score  \\\n",
      "0.1         0.1  XGBClassifier      0.94   0.009434     0.5  0.018519   \n",
      "0.2         0.2  XGBClassifier      0.94   0.011364     0.5  0.022222   \n",
      "0.3         0.3  XGBClassifier      0.94   0.012658     0.5  0.024691   \n",
      "0.4         0.4  XGBClassifier      0.94   0.014493     0.5  0.028169   \n",
      "0.5         0.5  XGBClassifier      0.94   0.016949     0.5  0.032787   \n",
      "0.6         0.6  XGBClassifier      0.94   0.020408     0.5  0.039216   \n",
      "0.7         0.7  XGBClassifier      0.94   0.024390     0.5  0.046512   \n",
      "0.8         0.8  XGBClassifier      0.94   0.025000     0.5  0.047619   \n",
      "0.9         0.9  XGBClassifier      0.94   0.030303     0.5  0.057143   \n",
      "\n",
      "     Auc_Score  \n",
      "0.1   0.929009  \n",
      "0.2   0.929009  \n",
      "0.3   0.929009  \n",
      "0.4   0.929009  \n",
      "0.5   0.929009  \n",
      "0.6   0.929009  \n",
      "0.7   0.929009  \n",
      "0.8   0.929009  \n",
      "0.9   0.929009  \n",
      "모델명: RandomForestClassifier\n",
      "학습 데이터 최적 파라미터\n",
      ": {'max_depth': 7, 'min_samples_split': 3}\n",
      "학습 데이터 최고 정확도\n",
      ": 0.984\n",
      "     Negative(0)  Positive(1)  y_pred\n",
      "0       0.559931     0.440069     0.0\n",
      "1       0.853070     0.146930     0.0\n",
      "2       1.000000     0.000000     0.0\n",
      "3       0.937875     0.062125     0.0\n",
      "4       0.983630     0.016370     0.0\n",
      "..           ...          ...     ...\n",
      "976     1.000000     0.000000     0.0\n",
      "977     1.000000     0.000000     0.0\n",
      "978     1.000000     0.000000     0.0\n",
      "979     0.000000     1.000000     1.0\n",
      "980     0.747463     0.252537     0.0\n",
      "\n",
      "[981 rows x 3 columns]\n",
      "단일 모델 results :      thresholds                  models  Accuracy  Precision  Recall  \\\n",
      "0.1         0.1  RandomForestClassifier     0.959   0.008547     1.0   \n",
      "0.2         0.2  RandomForestClassifier     0.959   0.011696     1.0   \n",
      "0.3         0.3  RandomForestClassifier     0.959   0.007752     0.5   \n",
      "0.4         0.4  RandomForestClassifier     0.959   0.013158     0.5   \n",
      "0.5         0.5  RandomForestClassifier     0.959   0.025000     0.5   \n",
      "0.6         0.6  RandomForestClassifier     0.959   0.027027     0.5   \n",
      "0.7         0.7  RandomForestClassifier     0.959   0.076923     0.5   \n",
      "0.8         0.8  RandomForestClassifier     0.959   1.000000     0.5   \n",
      "0.9         0.9  RandomForestClassifier     0.959   1.000000     0.5   \n",
      "\n",
      "     F1 score  Auc_Score  \n",
      "0.1  0.016949   0.921348  \n",
      "0.2  0.023121   0.921348  \n",
      "0.3  0.015267   0.921348  \n",
      "0.4  0.025641   0.921348  \n",
      "0.5  0.047619   0.921348  \n",
      "0.6  0.051282   0.921348  \n",
      "0.7  0.133333   0.921348  \n",
      "0.8  0.666667   0.921348  \n",
      "0.9  0.666667   0.921348  \n",
      "     thresholds                  models  Accuracy  Precision  Recall  \\\n",
      "0.1         0.1  RandomForestClassifier     0.959   0.008547     1.0   \n",
      "0.2         0.2  RandomForestClassifier     0.959   0.011696     1.0   \n",
      "0.3         0.3  RandomForestClassifier     0.959   0.007752     0.5   \n",
      "0.4         0.4  RandomForestClassifier     0.959   0.013158     0.5   \n",
      "0.5         0.5  RandomForestClassifier     0.959   0.025000     0.5   \n",
      "0.6         0.6  RandomForestClassifier     0.959   0.027027     0.5   \n",
      "0.7         0.7  RandomForestClassifier     0.959   0.076923     0.5   \n",
      "0.8         0.8  RandomForestClassifier     0.959   1.000000     0.5   \n",
      "0.9         0.9  RandomForestClassifier     0.959   1.000000     0.5   \n",
      "\n",
      "     F1 score  Auc_Score  \n",
      "0.1  0.016949   0.921348  \n",
      "0.2  0.023121   0.921348  \n",
      "0.3  0.015267   0.921348  \n",
      "0.4  0.025641   0.921348  \n",
      "0.5  0.047619   0.921348  \n",
      "0.6  0.051282   0.921348  \n",
      "0.7  0.133333   0.921348  \n",
      "0.8  0.666667   0.921348  \n",
      "0.9  0.666667   0.921348  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Auc_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.929009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.921348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     thresholds                  models  Accuracy  Precision  Recall  \\\n",
       "0.9         0.9           XGBClassifier     0.940   0.030303     0.5   \n",
       "0.8         0.8  RandomForestClassifier     0.959   1.000000     0.5   \n",
       "\n",
       "     F1 score  Auc_Score  \n",
       "0.9  0.057143   0.929009  \n",
       "0.8  0.666667   0.921348  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, accuracy_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression,  LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# df = pd.DataFrame(columns =['models','Accuracy','Precision', 'Recall', 'F1 score','Auc_Score'])\n",
    "\n",
    "\n",
    "\n",
    "class Model_Optimization():\n",
    "\n",
    "      def __init__(self):\n",
    "            \n",
    "            global model_df\n",
    "            model_df = pd.DataFrame(columns =['thresholds','models','Accuracy','Precision', 'Recall', 'F1 score','Auc_Score']) \n",
    "\n",
    "\n",
    "      #최적 파라미터 찾는 함수 ()\n",
    "      def grid(self,model_name, X_train=X_resampled_std, y_train=y_resampled_std, X_test=X_transition_05,y_test=y_transition_05):\n",
    "            global model_df\n",
    "\n",
    "            self.model_name = model_name\n",
    "            self.X_test = X_test\n",
    "            self.y_test = y_test\n",
    "            self.X_train = X_train\n",
    "            self.y_train  = y_train\n",
    "\n",
    "            if model_name == \"DecisionTreeClassifier\":\n",
    "                  dt = DecisionTreeClassifier()\n",
    "                  parameters = [{\"max_depth\": [3,5,7], \"min_samples_split\":[3,5,7]}]\n",
    "                  \n",
    "            elif model_name == \"RandomForestClassifier\":\n",
    "                  dt = RandomForestClassifier()\n",
    "                  parameters = [{\"max_depth\": [3,5,7], \"min_samples_split\":[3,5,7]}]\n",
    "                  \n",
    "            elif model_name == \"LogisticRegression\":\n",
    "                  dt = LogisticRegression()\n",
    "                  parameters = {'penalty':['l2', 'l1'],\n",
    "                  'C':[0.01, 0.1, 1, 5, 10]}\n",
    "                  \n",
    "            elif model_name == \"Linear SVM\": \n",
    "                  dt = SVC(probability=True)\n",
    "                  parameters = [{'kernel':['linear'], 'C':[0.001, 0.01, 0.025, 0.1, 1, 10, 100]}]\n",
    "                  \n",
    "            elif model_name == \"RBF SVM\": \n",
    "                  dt = SVC(probability=True)\n",
    "                  parameters = [{'gamma':[0.001, 0.01, 0.1, 1, 10, 100],'kernel':['rbf'],'C':[0.001, 0.01, 0.025, 0.1, 1, 10, 100]}]\n",
    "\n",
    "            elif model_name == \"AdaBoostClassifier\":\n",
    "                  dt= AdaBoostClassifier(random_state=0)\n",
    "                  parameters={'n_estimators':[5]}\n",
    "                  \n",
    "            elif model_name == \"GradientBoostingClassifier\":\n",
    "                  dt=GradientBoostingClassifier(random_state=0)\n",
    "                  parameters = {\n",
    "                  'n_estimators' : [100, 500],\n",
    "                  'learning_rate' : [0.05, 0.1]\n",
    "                              }\n",
    "\n",
    "            elif model_name == \"XGBClassifier\":\n",
    "                  dt=XGBClassifier(random_state=0,verbose=1)\n",
    "                  parameters={'n_estimators':[100, 500], 'learning_rate':[0.05, 0.1], 'max_depth':[3,4]}\n",
    "                  \n",
    "            # elif model_name == \"LGBMClassifier\":\n",
    "            #       dt=LGBMClassifier(random_state=0)\n",
    "            #       parameters={'n_estimators':[400,800], 'learning_rate':[0.05, 0.1] , 'max_depth':[3,4]}\n",
    "            \n",
    "            elif model_name == \"KNeighborsClassifier\":\n",
    "                  dt = KNeighborsClassifier()\n",
    "                  parameters = {'n_neighbors':[3]}\n",
    "                  \n",
    "            elif model_name == 'MLPClassifier':\n",
    "                  dt = MLPClassifier(random_state=0)\n",
    "                  parameters={'max_iter':[1000], 'hidden_layer_sizes':[1], 'activation':['logistic'],\n",
    "                              'solver':['sgd'], 'alpha':[0.01], 'batch_size':[32],\n",
    "                              'learning_rate_init':[0.1], 'max_iter':[500]}\n",
    "                  \n",
    "            elif model_name == 'GaussianProcessClassifier':\n",
    "                  dt = GaussianProcessClassifier(random_state=0)\n",
    "                  parameters={'kernel': [1.0*RBF(1.0)]}\n",
    "                  \n",
    "            elif model_name == 'GaussianNB':\n",
    "                  dt = GaussianNB()\n",
    "                  parameters={}\n",
    "                  \n",
    "            elif model_name =='QuadraticDiscriminantAnalysis':\n",
    "                  #선형판별분석\n",
    "                  dt = QuadraticDiscriminantAnalysis()\n",
    "                  parameters={}\n",
    "                  \n",
    "            # 최적 파라미터 찾기 \n",
    "            self.grid_dt  = GridSearchCV(dt, param_grid = parameters, cv=5, refit =True, n_jobs=-1)\n",
    "            self.grid_dt.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            print(f\"모델명: {model_name}\")\n",
    "            print(f\"학습 데이터 최적 파라미터\\n: {self.grid_dt.best_params_}\")\n",
    "            print(f\"학습 데이터 최고 정확도\\n: {self.grid_dt.best_score_:.3f}\")\n",
    "\n",
    "            #지도학습 알고리즘 \n",
    "            estimator = self.grid_dt.best_estimator_\n",
    "            y_pred = pd.DataFrame(estimator.predict(self.X_test))\n",
    "            y_pred_probability = pd.DataFrame(estimator.predict_proba(self.X_test))\n",
    "            # print(f\"예측 정확도\\n: {accuracy_score(self.y_test, y_pred):.3f}\")\n",
    "\n",
    "            prediction = pd.concat([y_pred_probability, y_pred], axis = 1)\n",
    "\n",
    "            prediction.columns = [\"Negative(0)\", \"Positive(1)\", \"y_pred\"]\n",
    "\n",
    "            print(prediction)\n",
    "            self.pred_proba_1 = np.array(prediction[\"Positive(1)\"]).reshape(-1, 1)\n",
    "            self.accuracy= round(accuracy_score(self.y_test, y_pred),3)\n",
    "            self.FPRs, self.TPRs, self.thresholds = roc_curve(self.y_test, self.pred_proba_1)\n",
    "            \n",
    "            return estimator\n",
    "\n",
    "\n",
    "\n",
    "      # 단일 모델 임계치별 score 출력 하는 함수 *주의  self.thresholds 값 내부 리스트 수정해줘야함 \n",
    "      def get_thresholds_score(self):\n",
    "            global model_df\n",
    "\n",
    "            \n",
    "            self.thresholds = [0.1, 0.2 , 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "            #평가지표용 리스트생성\n",
    "            precisions = []\n",
    "            recalls = []\n",
    "            f1_scores = []\n",
    "            auc_scores=[]\n",
    "            threshold_ =[]\n",
    "            \n",
    "            \n",
    "            \n",
    "            for threshold in self.thresholds:\n",
    "                  binarizer = Binarizer(threshold= threshold)\n",
    "                  # print(threshold)\n",
    "                  # 임계점 지정하여 Binariazer() 객체 생성\n",
    "                  pred_proba = binarizer.fit_transform(self.pred_proba_1)\n",
    "                  # print(pred_proba)\n",
    "                  # 임계점을 기준으로 데이터 변환\n",
    "\n",
    "                  precision = precision_score(self.y_test, pred_proba)\n",
    "                  recall = recall_score(self.y_test, pred_proba)\n",
    "                  f1score = f1_score(self.y_test, pred_proba)\n",
    "                  auc_score=roc_auc_score(self.y_test, self.pred_proba_1)\n",
    "\n",
    "                  precisions.append(precision)\n",
    "                  recalls.append(recall)\n",
    "                  f1_scores.append(f1score)\n",
    "                  auc_scores.append(auc_score)\n",
    "                  threshold_.append(threshold)\n",
    "                  \n",
    "\n",
    "            results = pd.DataFrame(data = {\"thresholds\":threshold_, \"models\":self.model_name,\"Accuracy\":self.accuracy,\"Precision\": precisions,\n",
    "                                          \"Recall\": recalls,\n",
    "                                          \"F1 score\": f1_scores,\"Auc_Score\":auc_scores}, index = self.thresholds)                 \n",
    "\n",
    "            print(f'단일 모델 results : {results}')      \n",
    "            return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      #모든 모델 성능 비교 함수 \n",
    "      def get_model_socre(self,input_list):\n",
    "            global model_df \n",
    "\n",
    "            mod = Model_Optimization()\n",
    "            for i in tqdm(input_list):\n",
    "                  mod.grid(model_name=i)\n",
    "                  results_df = mod.get_thresholds_score()\n",
    "\n",
    "                  #평가지표 데이터 프레임화 \n",
    "                  print(results_df)\n",
    "                  #기준 평가지표로 정렬\n",
    "                  results_df.sort_values(\"F1 score\", ascending=False, inplace=True)\n",
    "                  new_model_df= results_df.iloc[:1]\n",
    "                  model_df = pd.concat([model_df,new_model_df])\n",
    "                  \n",
    "            return model_df\n",
    "        \n",
    "list = ['XGBClassifier','RandomForestClassifier']\n",
    "model = Model_Optimization()\n",
    "model.get_model_socre(list)\n",
    "model_df.to_csv('../Data/result/2005년_확장.csv',index=False, encoding='cp949')\n",
    "\n",
    "model_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03970fbb48114330b08ad242601327b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:59:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:59:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "모델명: XGBClassifier\n",
      "학습 데이터 최적 파라미터\n",
      ": {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "학습 데이터 최고 정확도\n",
      ": 0.997\n",
      "       Negative(0)   Positive(1)  y_pred\n",
      "0     9.982249e-01  1.775139e-03     0.0\n",
      "1     9.991938e-01  8.062070e-04     0.0\n",
      "2     9.999996e-01  4.048274e-07     0.0\n",
      "3     9.999959e-01  4.060943e-06     0.0\n",
      "4     9.903989e-01  9.601033e-03     0.0\n",
      "...            ...           ...     ...\n",
      "1016  9.999188e-01  8.125645e-05     0.0\n",
      "1017  1.072884e-06  9.999989e-01     1.0\n",
      "1018  9.705179e-01  2.948212e-02     0.0\n",
      "1019  1.192093e-07  9.999999e-01     1.0\n",
      "1020  9.999972e-01  2.824402e-06     0.0\n",
      "\n",
      "[1021 rows x 3 columns]\n",
      "단일 모델 results :      thresholds         models  Accuracy  Precision    Recall  F1 score  \\\n",
      "0.1         0.1  XGBClassifier     0.976   0.207547  0.733333  0.323529   \n",
      "0.2         0.2  XGBClassifier     0.976   0.232558  0.666667  0.344828   \n",
      "0.3         0.3  XGBClassifier     0.976   0.250000  0.666667  0.363636   \n",
      "0.4         0.4  XGBClassifier     0.976   0.312500  0.666667  0.425532   \n",
      "0.5         0.5  XGBClassifier     0.976   0.333333  0.600000  0.428571   \n",
      "0.6         0.6  XGBClassifier     0.976   0.391304  0.600000  0.473684   \n",
      "0.7         0.7  XGBClassifier     0.976   0.450000  0.600000  0.514286   \n",
      "0.8         0.8  XGBClassifier     0.976   0.450000  0.600000  0.514286   \n",
      "0.9         0.9  XGBClassifier     0.976   0.529412  0.600000  0.562500   \n",
      "\n",
      "     Auc_Score  \n",
      "0.1    0.92611  \n",
      "0.2    0.92611  \n",
      "0.3    0.92611  \n",
      "0.4    0.92611  \n",
      "0.5    0.92611  \n",
      "0.6    0.92611  \n",
      "0.7    0.92611  \n",
      "0.8    0.92611  \n",
      "0.9    0.92611  \n",
      "     thresholds         models  Accuracy  Precision    Recall  F1 score  \\\n",
      "0.1         0.1  XGBClassifier     0.976   0.207547  0.733333  0.323529   \n",
      "0.2         0.2  XGBClassifier     0.976   0.232558  0.666667  0.344828   \n",
      "0.3         0.3  XGBClassifier     0.976   0.250000  0.666667  0.363636   \n",
      "0.4         0.4  XGBClassifier     0.976   0.312500  0.666667  0.425532   \n",
      "0.5         0.5  XGBClassifier     0.976   0.333333  0.600000  0.428571   \n",
      "0.6         0.6  XGBClassifier     0.976   0.391304  0.600000  0.473684   \n",
      "0.7         0.7  XGBClassifier     0.976   0.450000  0.600000  0.514286   \n",
      "0.8         0.8  XGBClassifier     0.976   0.450000  0.600000  0.514286   \n",
      "0.9         0.9  XGBClassifier     0.976   0.529412  0.600000  0.562500   \n",
      "\n",
      "     Auc_Score  \n",
      "0.1    0.92611  \n",
      "0.2    0.92611  \n",
      "0.3    0.92611  \n",
      "0.4    0.92611  \n",
      "0.5    0.92611  \n",
      "0.6    0.92611  \n",
      "0.7    0.92611  \n",
      "0.8    0.92611  \n",
      "0.9    0.92611  \n",
      "모델명: RandomForestClassifier\n",
      "학습 데이터 최적 파라미터\n",
      ": {'max_depth': 7, 'min_samples_split': 7}\n",
      "학습 데이터 최고 정확도\n",
      ": 0.985\n",
      "      Negative(0)  Positive(1)  y_pred\n",
      "0        0.808681     0.191319     0.0\n",
      "1        0.896729     0.103271     0.0\n",
      "2        1.000000     0.000000     0.0\n",
      "3        1.000000     0.000000     0.0\n",
      "4        0.767768     0.232232     0.0\n",
      "...           ...          ...     ...\n",
      "1016     0.988228     0.011772     0.0\n",
      "1017     0.000000     1.000000     1.0\n",
      "1018     0.762676     0.237324     0.0\n",
      "1019     0.000000     1.000000     1.0\n",
      "1020     0.957742     0.042258     0.0\n",
      "\n",
      "[1021 rows x 3 columns]\n",
      "단일 모델 results :      thresholds                  models  Accuracy  Precision    Recall  \\\n",
      "0.1         0.1  RandomForestClassifier     0.982   0.068063  0.866667   \n",
      "0.2         0.2  RandomForestClassifier     0.982   0.104000  0.866667   \n",
      "0.3         0.3  RandomForestClassifier     0.982   0.142857  0.800000   \n",
      "0.4         0.4  RandomForestClassifier     0.982   0.212766  0.666667   \n",
      "0.5         0.5  RandomForestClassifier     0.982   0.434783  0.666667   \n",
      "0.6         0.6  RandomForestClassifier     0.982   0.500000  0.600000   \n",
      "0.7         0.7  RandomForestClassifier     0.982   0.562500  0.600000   \n",
      "0.8         0.8  RandomForestClassifier     0.982   1.000000  0.600000   \n",
      "0.9         0.9  RandomForestClassifier     0.982   1.000000  0.533333   \n",
      "\n",
      "     F1 score  Auc_Score  \n",
      "0.1  0.126214    0.94662  \n",
      "0.2  0.185714    0.94662  \n",
      "0.3  0.242424    0.94662  \n",
      "0.4  0.322581    0.94662  \n",
      "0.5  0.526316    0.94662  \n",
      "0.6  0.545455    0.94662  \n",
      "0.7  0.580645    0.94662  \n",
      "0.8  0.750000    0.94662  \n",
      "0.9  0.695652    0.94662  \n",
      "     thresholds                  models  Accuracy  Precision    Recall  \\\n",
      "0.1         0.1  RandomForestClassifier     0.982   0.068063  0.866667   \n",
      "0.2         0.2  RandomForestClassifier     0.982   0.104000  0.866667   \n",
      "0.3         0.3  RandomForestClassifier     0.982   0.142857  0.800000   \n",
      "0.4         0.4  RandomForestClassifier     0.982   0.212766  0.666667   \n",
      "0.5         0.5  RandomForestClassifier     0.982   0.434783  0.666667   \n",
      "0.6         0.6  RandomForestClassifier     0.982   0.500000  0.600000   \n",
      "0.7         0.7  RandomForestClassifier     0.982   0.562500  0.600000   \n",
      "0.8         0.8  RandomForestClassifier     0.982   1.000000  0.600000   \n",
      "0.9         0.9  RandomForestClassifier     0.982   1.000000  0.533333   \n",
      "\n",
      "     F1 score  Auc_Score  \n",
      "0.1  0.126214    0.94662  \n",
      "0.2  0.185714    0.94662  \n",
      "0.3  0.242424    0.94662  \n",
      "0.4  0.322581    0.94662  \n",
      "0.5  0.526316    0.94662  \n",
      "0.6  0.545455    0.94662  \n",
      "0.7  0.580645    0.94662  \n",
      "0.8  0.750000    0.94662  \n",
      "0.9  0.695652    0.94662  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Auc_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.92611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.94662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     thresholds                  models  Accuracy  Precision  Recall  \\\n",
       "0.9         0.9           XGBClassifier     0.976   0.529412     0.6   \n",
       "0.8         0.8  RandomForestClassifier     0.982   1.000000     0.6   \n",
       "\n",
       "     F1 score  Auc_Score  \n",
       "0.9    0.5625    0.92611  \n",
       "0.8    0.7500    0.94662  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, accuracy_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression,  LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# df = pd.DataFrame(columns =['models','Accuracy','Precision', 'Recall', 'F1 score','Auc_Score'])\n",
    "\n",
    "\n",
    "\n",
    "class Model_Optimization():\n",
    "\n",
    "      def __init__(self):\n",
    "            \n",
    "            global model_df\n",
    "            model_df = pd.DataFrame(columns =['thresholds','models','Accuracy','Precision', 'Recall', 'F1 score','Auc_Score']) \n",
    "\n",
    "\n",
    "      #최적 파라미터 찾는 함수 ()\n",
    "      def grid(self,model_name, X_train=X_resampled_std, y_train=y_resampled_std, X_test=X_transition_11,y_test=y_transition_11):\n",
    "            global model_df\n",
    "\n",
    "            self.model_name = model_name\n",
    "            self.X_test = X_test\n",
    "            self.y_test = y_test\n",
    "            self.X_train = X_train\n",
    "            self.y_train  = y_train\n",
    "\n",
    "            if model_name == \"DecisionTreeClassifier\":\n",
    "                  dt = DecisionTreeClassifier()\n",
    "                  parameters = [{\"max_depth\": [3,5,7], \"min_samples_split\":[3,5,7]}]\n",
    "                  \n",
    "            elif model_name == \"RandomForestClassifier\":\n",
    "                  dt = RandomForestClassifier()\n",
    "                  parameters = [{\"max_depth\": [3,5,7], \"min_samples_split\":[3,5,7]}]\n",
    "                  \n",
    "            elif model_name == \"LogisticRegression\":\n",
    "                  dt = LogisticRegression()\n",
    "                  parameters = {'penalty':['l2', 'l1'],\n",
    "                  'C':[0.01, 0.1, 1, 5, 10]}\n",
    "                  \n",
    "            elif model_name == \"Linear SVM\": \n",
    "                  dt = SVC(probability=True)\n",
    "                  parameters = [{'kernel':['linear'], 'C':[0.001, 0.01, 0.025, 0.1, 1, 10, 100]}]\n",
    "                  \n",
    "            elif model_name == \"RBF SVM\": \n",
    "                  dt = SVC(probability=True)\n",
    "                  parameters = [{'gamma':[0.001, 0.01, 0.1, 1, 10, 100],'kernel':['rbf'],'C':[0.001, 0.01, 0.025, 0.1, 1, 10, 100]}]\n",
    "\n",
    "            elif model_name == \"AdaBoostClassifier\":\n",
    "                  dt= AdaBoostClassifier(random_state=0)\n",
    "                  parameters={'n_estimators':[5]}\n",
    "                  \n",
    "            elif model_name == \"GradientBoostingClassifier\":\n",
    "                  dt=GradientBoostingClassifier(random_state=0)\n",
    "                  parameters = {\n",
    "                  'n_estimators' : [100, 500],\n",
    "                  'learning_rate' : [0.05, 0.1]\n",
    "                              }\n",
    "\n",
    "            elif model_name == \"XGBClassifier\":\n",
    "                  dt=XGBClassifier(random_state=0,verbose=1)\n",
    "                  parameters={'n_estimators':[100, 500], 'learning_rate':[0.05, 0.1], 'max_depth':[3,4]}\n",
    "                  \n",
    "            # elif model_name == \"LGBMClassifier\":\n",
    "            #       dt=LGBMClassifier(random_state=0)\n",
    "            #       parameters={'n_estimators':[400,800], 'learning_rate':[0.05, 0.1] , 'max_depth':[3,4]}\n",
    "            \n",
    "            elif model_name == \"KNeighborsClassifier\":\n",
    "                  dt = KNeighborsClassifier()\n",
    "                  parameters = {'n_neighbors':[3]}\n",
    "                  \n",
    "            elif model_name == 'MLPClassifier':\n",
    "                  dt = MLPClassifier(random_state=0)\n",
    "                  parameters={'max_iter':[1000], 'hidden_layer_sizes':[1], 'activation':['logistic'],\n",
    "                              'solver':['sgd'], 'alpha':[0.01], 'batch_size':[32],\n",
    "                              'learning_rate_init':[0.1], 'max_iter':[500]}\n",
    "                  \n",
    "            elif model_name == 'GaussianProcessClassifier':\n",
    "                  dt = GaussianProcessClassifier(random_state=0)\n",
    "                  parameters={'kernel': [1.0*RBF(1.0)]}\n",
    "                  \n",
    "            elif model_name == 'GaussianNB':\n",
    "                  dt = GaussianNB()\n",
    "                  parameters={}\n",
    "                  \n",
    "            elif model_name =='QuadraticDiscriminantAnalysis':\n",
    "                  #선형판별분석\n",
    "                  dt = QuadraticDiscriminantAnalysis()\n",
    "                  parameters={}\n",
    "                  \n",
    "            # 최적 파라미터 찾기 \n",
    "            self.grid_dt  = GridSearchCV(dt, param_grid = parameters, cv=5, refit =True, n_jobs=-1)\n",
    "            self.grid_dt.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            print(f\"모델명: {model_name}\")\n",
    "            print(f\"학습 데이터 최적 파라미터\\n: {self.grid_dt.best_params_}\")\n",
    "            print(f\"학습 데이터 최고 정확도\\n: {self.grid_dt.best_score_:.3f}\")\n",
    "\n",
    "            #지도학습 알고리즘 \n",
    "            estimator = self.grid_dt.best_estimator_\n",
    "            y_pred = pd.DataFrame(estimator.predict(self.X_test))\n",
    "            y_pred_probability = pd.DataFrame(estimator.predict_proba(self.X_test))\n",
    "            # print(f\"예측 정확도\\n: {accuracy_score(self.y_test, y_pred):.3f}\")\n",
    "\n",
    "            prediction = pd.concat([y_pred_probability, y_pred], axis = 1)\n",
    "\n",
    "            prediction.columns = [\"Negative(0)\", \"Positive(1)\", \"y_pred\"]\n",
    "\n",
    "            print(prediction)\n",
    "            self.pred_proba_1 = np.array(prediction[\"Positive(1)\"]).reshape(-1, 1)\n",
    "            self.accuracy= round(accuracy_score(self.y_test, y_pred),3)\n",
    "            self.FPRs, self.TPRs, self.thresholds = roc_curve(self.y_test, self.pred_proba_1)\n",
    "            \n",
    "            return estimator\n",
    "\n",
    "\n",
    "\n",
    "      # 단일 모델 임계치별 score 출력 하는 함수 *주의  self.thresholds 값 내부 리스트 수정해줘야함 \n",
    "      def get_thresholds_score(self):\n",
    "            global model_df\n",
    "\n",
    "            \n",
    "            self.thresholds = [0.1, 0.2 , 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "            #평가지표용 리스트생성\n",
    "            precisions = []\n",
    "            recalls = []\n",
    "            f1_scores = []\n",
    "            auc_scores=[]\n",
    "            threshold_ =[]\n",
    "            \n",
    "            \n",
    "            \n",
    "            for threshold in self.thresholds:\n",
    "                  binarizer = Binarizer(threshold= threshold)\n",
    "                  # print(threshold)\n",
    "                  # 임계점 지정하여 Binariazer() 객체 생성\n",
    "                  pred_proba = binarizer.fit_transform(self.pred_proba_1)\n",
    "                  # print(pred_proba)\n",
    "                  # 임계점을 기준으로 데이터 변환\n",
    "\n",
    "                  precision = precision_score(self.y_test, pred_proba)\n",
    "                  recall = recall_score(self.y_test, pred_proba)\n",
    "                  f1score = f1_score(self.y_test, pred_proba)\n",
    "                  auc_score=roc_auc_score(self.y_test, self.pred_proba_1)\n",
    "\n",
    "                  precisions.append(precision)\n",
    "                  recalls.append(recall)\n",
    "                  f1_scores.append(f1score)\n",
    "                  auc_scores.append(auc_score)\n",
    "                  threshold_.append(threshold)\n",
    "                  \n",
    "\n",
    "            results = pd.DataFrame(data = {\"thresholds\":threshold_, \"models\":self.model_name,\"Accuracy\":self.accuracy,\"Precision\": precisions,\n",
    "                                          \"Recall\": recalls,\n",
    "                                          \"F1 score\": f1_scores,\"Auc_Score\":auc_scores}, index = self.thresholds)                 \n",
    "\n",
    "            print(f'단일 모델 results : {results}')      \n",
    "            return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      #모든 모델 성능 비교 함수 \n",
    "      def get_model_socre(self,input_list):\n",
    "            global model_df \n",
    "\n",
    "            mod = Model_Optimization()\n",
    "            for i in tqdm(input_list):\n",
    "                  mod.grid(model_name=i)\n",
    "                  results_df = mod.get_thresholds_score()\n",
    "\n",
    "                  #평가지표 데이터 프레임화 \n",
    "                  print(results_df)\n",
    "                  #기준 평가지표로 정렬\n",
    "                  results_df.sort_values(\"F1 score\", ascending=False, inplace=True)\n",
    "                  new_model_df= results_df.iloc[:1]\n",
    "                  model_df = pd.concat([model_df,new_model_df])\n",
    "                  \n",
    "            return model_df\n",
    "        \n",
    "list = ['XGBClassifier','RandomForestClassifier']\n",
    "model = Model_Optimization()\n",
    "model.get_model_socre(list)\n",
    "model_df.to_csv('../Data/result/2011년_확장.csv',index=False, encoding='cp949')\n",
    "\n",
    "model_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9fa02d787f4a338f7ad138afe893b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:59:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:59:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "모델명: XGBClassifier\n",
      "학습 데이터 최적 파라미터\n",
      ": {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "학습 데이터 최고 정확도\n",
      ": 0.997\n",
      "      Negative(0)   Positive(1)  y_pred\n",
      "0        0.999963  3.725031e-05     0.0\n",
      "1        0.999675  3.252227e-04     0.0\n",
      "2        0.999999  1.145775e-06     0.0\n",
      "3        0.999972  2.843297e-05     0.0\n",
      "4        0.969854  3.014628e-02     0.0\n",
      "...           ...           ...     ...\n",
      "1040     0.368205  6.317948e-01     1.0\n",
      "1041     0.383081  6.169186e-01     1.0\n",
      "1042     0.046744  9.532562e-01     1.0\n",
      "1043     0.999999  9.093578e-07     0.0\n",
      "1044     0.000054  9.999455e-01     1.0\n",
      "\n",
      "[1045 rows x 3 columns]\n",
      "단일 모델 results :      thresholds         models  Accuracy  Precision    Recall  F1 score  \\\n",
      "0.1         0.1  XGBClassifier     0.978   0.155172  0.818182  0.260870   \n",
      "0.2         0.2  XGBClassifier     0.978   0.187500  0.818182  0.305085   \n",
      "0.3         0.3  XGBClassifier     0.978   0.230769  0.818182  0.360000   \n",
      "0.4         0.4  XGBClassifier     0.978   0.250000  0.818182  0.382979   \n",
      "0.5         0.5  XGBClassifier     0.978   0.300000  0.818182  0.439024   \n",
      "0.6         0.6  XGBClassifier     0.978   0.346154  0.818182  0.486486   \n",
      "0.7         0.7  XGBClassifier     0.978   0.350000  0.636364  0.451613   \n",
      "0.8         0.8  XGBClassifier     0.978   0.368421  0.636364  0.466667   \n",
      "0.9         0.9  XGBClassifier     0.978   0.428571  0.545455  0.480000   \n",
      "\n",
      "     Auc_Score  \n",
      "0.1    0.90531  \n",
      "0.2    0.90531  \n",
      "0.3    0.90531  \n",
      "0.4    0.90531  \n",
      "0.5    0.90531  \n",
      "0.6    0.90531  \n",
      "0.7    0.90531  \n",
      "0.8    0.90531  \n",
      "0.9    0.90531  \n",
      "     thresholds         models  Accuracy  Precision    Recall  F1 score  \\\n",
      "0.1         0.1  XGBClassifier     0.978   0.155172  0.818182  0.260870   \n",
      "0.2         0.2  XGBClassifier     0.978   0.187500  0.818182  0.305085   \n",
      "0.3         0.3  XGBClassifier     0.978   0.230769  0.818182  0.360000   \n",
      "0.4         0.4  XGBClassifier     0.978   0.250000  0.818182  0.382979   \n",
      "0.5         0.5  XGBClassifier     0.978   0.300000  0.818182  0.439024   \n",
      "0.6         0.6  XGBClassifier     0.978   0.346154  0.818182  0.486486   \n",
      "0.7         0.7  XGBClassifier     0.978   0.350000  0.636364  0.451613   \n",
      "0.8         0.8  XGBClassifier     0.978   0.368421  0.636364  0.466667   \n",
      "0.9         0.9  XGBClassifier     0.978   0.428571  0.545455  0.480000   \n",
      "\n",
      "     Auc_Score  \n",
      "0.1    0.90531  \n",
      "0.2    0.90531  \n",
      "0.3    0.90531  \n",
      "0.4    0.90531  \n",
      "0.5    0.90531  \n",
      "0.6    0.90531  \n",
      "0.7    0.90531  \n",
      "0.8    0.90531  \n",
      "0.9    0.90531  \n",
      "모델명: RandomForestClassifier\n",
      "학습 데이터 최적 파라미터\n",
      ": {'max_depth': 7, 'min_samples_split': 3}\n",
      "학습 데이터 최고 정확도\n",
      ": 0.985\n",
      "      Negative(0)  Positive(1)  y_pred\n",
      "0        0.881379     0.118621     0.0\n",
      "1        0.824669     0.175331     0.0\n",
      "2        1.000000     0.000000     0.0\n",
      "3        1.000000     0.000000     0.0\n",
      "4        0.731519     0.268481     0.0\n",
      "...           ...          ...     ...\n",
      "1040     0.371833     0.628167     1.0\n",
      "1041     0.359950     0.640050     1.0\n",
      "1042     0.112416     0.887584     1.0\n",
      "1043     1.000000     0.000000     0.0\n",
      "1044     0.017706     0.982294     1.0\n",
      "\n",
      "[1045 rows x 3 columns]\n",
      "단일 모델 results :      thresholds                  models  Accuracy  Precision    Recall  \\\n",
      "0.1         0.1  RandomForestClassifier     0.981   0.045872  0.909091   \n",
      "0.2         0.2  RandomForestClassifier     0.981   0.065217  0.818182   \n",
      "0.3         0.3  RandomForestClassifier     0.981   0.108434  0.818182   \n",
      "0.4         0.4  RandomForestClassifier     0.981   0.230769  0.818182   \n",
      "0.5         0.5  RandomForestClassifier     0.981   0.333333  0.818182   \n",
      "0.6         0.6  RandomForestClassifier     0.981   0.473684  0.818182   \n",
      "0.7         0.7  RandomForestClassifier     0.981   0.636364  0.636364   \n",
      "0.8         0.8  RandomForestClassifier     0.981   1.000000  0.545455   \n",
      "0.9         0.9  RandomForestClassifier     0.981   1.000000  0.363636   \n",
      "\n",
      "     F1 score  Auc_Score  \n",
      "0.1  0.087336   0.911904  \n",
      "0.2  0.120805   0.911904  \n",
      "0.3  0.191489   0.911904  \n",
      "0.4  0.360000   0.911904  \n",
      "0.5  0.473684   0.911904  \n",
      "0.6  0.600000   0.911904  \n",
      "0.7  0.636364   0.911904  \n",
      "0.8  0.705882   0.911904  \n",
      "0.9  0.533333   0.911904  \n",
      "     thresholds                  models  Accuracy  Precision    Recall  \\\n",
      "0.1         0.1  RandomForestClassifier     0.981   0.045872  0.909091   \n",
      "0.2         0.2  RandomForestClassifier     0.981   0.065217  0.818182   \n",
      "0.3         0.3  RandomForestClassifier     0.981   0.108434  0.818182   \n",
      "0.4         0.4  RandomForestClassifier     0.981   0.230769  0.818182   \n",
      "0.5         0.5  RandomForestClassifier     0.981   0.333333  0.818182   \n",
      "0.6         0.6  RandomForestClassifier     0.981   0.473684  0.818182   \n",
      "0.7         0.7  RandomForestClassifier     0.981   0.636364  0.636364   \n",
      "0.8         0.8  RandomForestClassifier     0.981   1.000000  0.545455   \n",
      "0.9         0.9  RandomForestClassifier     0.981   1.000000  0.363636   \n",
      "\n",
      "     F1 score  Auc_Score  \n",
      "0.1  0.087336   0.911904  \n",
      "0.2  0.120805   0.911904  \n",
      "0.3  0.191489   0.911904  \n",
      "0.4  0.360000   0.911904  \n",
      "0.5  0.473684   0.911904  \n",
      "0.6  0.600000   0.911904  \n",
      "0.7  0.636364   0.911904  \n",
      "0.8  0.705882   0.911904  \n",
      "0.9  0.533333   0.911904  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Auc_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.905310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.911904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     thresholds                  models  Accuracy  Precision    Recall  \\\n",
       "0.6         0.6           XGBClassifier     0.978   0.346154  0.818182   \n",
       "0.8         0.8  RandomForestClassifier     0.981   1.000000  0.545455   \n",
       "\n",
       "     F1 score  Auc_Score  \n",
       "0.6  0.486486   0.905310  \n",
       "0.8  0.705882   0.911904  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, accuracy_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression,  LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# df = pd.DataFrame(columns =['models','Accuracy','Precision', 'Recall', 'F1 score','Auc_Score'])\n",
    "\n",
    "\n",
    "\n",
    "class Model_Optimization():\n",
    "\n",
    "      def __init__(self):\n",
    "            \n",
    "            global model_df\n",
    "            model_df = pd.DataFrame(columns =['thresholds','models','Accuracy','Precision', 'Recall', 'F1 score','Auc_Score']) \n",
    "\n",
    "\n",
    "      #최적 파라미터 찾는 함수 ()\n",
    "      def grid(self,model_name, X_train=X_resampled_std, y_train=y_resampled_std, X_test=X_transition_13,y_test=y_transition_13):\n",
    "            global model_df\n",
    "\n",
    "            self.model_name = model_name\n",
    "            self.X_test = X_test\n",
    "            self.y_test = y_test\n",
    "            self.X_train = X_train\n",
    "            self.y_train  = y_train\n",
    "\n",
    "            if model_name == \"DecisionTreeClassifier\":\n",
    "                  dt = DecisionTreeClassifier()\n",
    "                  parameters = [{\"max_depth\": [3,5,7], \"min_samples_split\":[3,5,7]}]\n",
    "                  \n",
    "            elif model_name == \"RandomForestClassifier\":\n",
    "                  dt = RandomForestClassifier()\n",
    "                  parameters = [{\"max_depth\": [3,5,7], \"min_samples_split\":[3,5,7]}]\n",
    "                  \n",
    "            elif model_name == \"LogisticRegression\":\n",
    "                  dt = LogisticRegression()\n",
    "                  parameters = {'penalty':['l2', 'l1'],\n",
    "                  'C':[0.01, 0.1, 1, 5, 10]}\n",
    "                  \n",
    "            elif model_name == \"Linear SVM\": \n",
    "                  dt = SVC(probability=True)\n",
    "                  parameters = [{'kernel':['linear'], 'C':[0.001, 0.01, 0.025, 0.1, 1, 10, 100]}]\n",
    "                  \n",
    "            elif model_name == \"RBF SVM\": \n",
    "                  dt = SVC(probability=True)\n",
    "                  parameters = [{'gamma':[0.001, 0.01, 0.1, 1, 10, 100],'kernel':['rbf'],'C':[0.001, 0.01, 0.025, 0.1, 1, 10, 100]}]\n",
    "\n",
    "            elif model_name == \"AdaBoostClassifier\":\n",
    "                  dt= AdaBoostClassifier(random_state=0)\n",
    "                  parameters={'n_estimators':[5]}\n",
    "                  \n",
    "            elif model_name == \"GradientBoostingClassifier\":\n",
    "                  dt=GradientBoostingClassifier(random_state=0)\n",
    "                  parameters = {\n",
    "                  'n_estimators' : [100, 500],\n",
    "                  'learning_rate' : [0.05, 0.1]\n",
    "                              }\n",
    "\n",
    "            elif model_name == \"XGBClassifier\":\n",
    "                  dt=XGBClassifier(random_state=0,verbose=1)\n",
    "                  parameters={'n_estimators':[100, 500], 'learning_rate':[0.05, 0.1], 'max_depth':[3,4]}\n",
    "                  \n",
    "            # elif model_name == \"LGBMClassifier\":\n",
    "            #       dt=LGBMClassifier(random_state=0)\n",
    "            #       parameters={'n_estimators':[400,800], 'learning_rate':[0.05, 0.1] , 'max_depth':[3,4]}\n",
    "            \n",
    "            elif model_name == \"KNeighborsClassifier\":\n",
    "                  dt = KNeighborsClassifier()\n",
    "                  parameters = {'n_neighbors':[3]}\n",
    "                  \n",
    "            elif model_name == 'MLPClassifier':\n",
    "                  dt = MLPClassifier(random_state=0)\n",
    "                  parameters={'max_iter':[1000], 'hidden_layer_sizes':[1], 'activation':['logistic'],\n",
    "                              'solver':['sgd'], 'alpha':[0.01], 'batch_size':[32],\n",
    "                              'learning_rate_init':[0.1], 'max_iter':[500]}\n",
    "                  \n",
    "            elif model_name == 'GaussianProcessClassifier':\n",
    "                  dt = GaussianProcessClassifier(random_state=0)\n",
    "                  parameters={'kernel': [1.0*RBF(1.0)]}\n",
    "                  \n",
    "            elif model_name == 'GaussianNB':\n",
    "                  dt = GaussianNB()\n",
    "                  parameters={}\n",
    "                  \n",
    "            elif model_name =='QuadraticDiscriminantAnalysis':\n",
    "                  #선형판별분석\n",
    "                  dt = QuadraticDiscriminantAnalysis()\n",
    "                  parameters={}\n",
    "                  \n",
    "            # 최적 파라미터 찾기 \n",
    "            self.grid_dt  = GridSearchCV(dt, param_grid = parameters, cv=5, refit =True, n_jobs=-1)\n",
    "            self.grid_dt.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            print(f\"모델명: {model_name}\")\n",
    "            print(f\"학습 데이터 최적 파라미터\\n: {self.grid_dt.best_params_}\")\n",
    "            print(f\"학습 데이터 최고 정확도\\n: {self.grid_dt.best_score_:.3f}\")\n",
    "\n",
    "            #지도학습 알고리즘 \n",
    "            estimator = self.grid_dt.best_estimator_\n",
    "            y_pred = pd.DataFrame(estimator.predict(self.X_test))\n",
    "            y_pred_probability = pd.DataFrame(estimator.predict_proba(self.X_test))\n",
    "            # print(f\"예측 정확도\\n: {accuracy_score(self.y_test, y_pred):.3f}\")\n",
    "\n",
    "            prediction = pd.concat([y_pred_probability, y_pred], axis = 1)\n",
    "\n",
    "            prediction.columns = [\"Negative(0)\", \"Positive(1)\", \"y_pred\"]\n",
    "\n",
    "            print(prediction)\n",
    "            self.pred_proba_1 = np.array(prediction[\"Positive(1)\"]).reshape(-1, 1)\n",
    "            self.accuracy= round(accuracy_score(self.y_test, y_pred),3)\n",
    "            self.FPRs, self.TPRs, self.thresholds = roc_curve(self.y_test, self.pred_proba_1)\n",
    "            \n",
    "            return estimator\n",
    "\n",
    "\n",
    "\n",
    "      # 단일 모델 임계치별 score 출력 하는 함수 *주의  self.thresholds 값 내부 리스트 수정해줘야함 \n",
    "      def get_thresholds_score(self):\n",
    "            global model_df\n",
    "\n",
    "            \n",
    "            self.thresholds = [0.1, 0.2 , 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "            #평가지표용 리스트생성\n",
    "            precisions = []\n",
    "            recalls = []\n",
    "            f1_scores = []\n",
    "            auc_scores=[]\n",
    "            threshold_ =[]\n",
    "            \n",
    "            \n",
    "            \n",
    "            for threshold in self.thresholds:\n",
    "                  binarizer = Binarizer(threshold= threshold)\n",
    "                  # print(threshold)\n",
    "                  # 임계점 지정하여 Binariazer() 객체 생성\n",
    "                  pred_proba = binarizer.fit_transform(self.pred_proba_1)\n",
    "                  # print(pred_proba)\n",
    "                  # 임계점을 기준으로 데이터 변환\n",
    "\n",
    "                  precision = precision_score(self.y_test, pred_proba)\n",
    "                  recall = recall_score(self.y_test, pred_proba)\n",
    "                  f1score = f1_score(self.y_test, pred_proba)\n",
    "                  auc_score=roc_auc_score(self.y_test, self.pred_proba_1)\n",
    "\n",
    "                  precisions.append(precision)\n",
    "                  recalls.append(recall)\n",
    "                  f1_scores.append(f1score)\n",
    "                  auc_scores.append(auc_score)\n",
    "                  threshold_.append(threshold)\n",
    "                  \n",
    "\n",
    "            results = pd.DataFrame(data = {\"thresholds\":threshold_, \"models\":self.model_name,\"Accuracy\":self.accuracy,\"Precision\": precisions,\n",
    "                                          \"Recall\": recalls,\n",
    "                                          \"F1 score\": f1_scores,\"Auc_Score\":auc_scores}, index = self.thresholds)                 \n",
    "\n",
    "            print(f'단일 모델 results : {results}')      \n",
    "            return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      #모든 모델 성능 비교 함수 \n",
    "      def get_model_socre(self,input_list):\n",
    "            global model_df \n",
    "\n",
    "            mod = Model_Optimization()\n",
    "            for i in tqdm(input_list):\n",
    "                  mod.grid(model_name=i)\n",
    "                  results_df = mod.get_thresholds_score()\n",
    "\n",
    "                  #평가지표 데이터 프레임화 \n",
    "                  print(results_df)\n",
    "                  #기준 평가지표로 정렬\n",
    "                  results_df.sort_values(\"F1 score\", ascending=False, inplace=True)\n",
    "                  new_model_df= results_df.iloc[:1]\n",
    "                  model_df = pd.concat([model_df,new_model_df])\n",
    "                  \n",
    "            return model_df\n",
    "        \n",
    "list = ['XGBClassifier','RandomForestClassifier']\n",
    "model = Model_Optimization()\n",
    "model.get_model_socre(list)\n",
    "model_df.to_csv('../Data/result/2013년_확장.csv',index=False, encoding='cp949')\n",
    "\n",
    "model_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd51016ab23f43c2a34ca61936d87dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:00:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:00:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "모델명: XGBClassifier\n",
      "학습 데이터 최적 파라미터\n",
      ": {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "학습 데이터 최고 정확도\n",
      ": 0.997\n",
      "      Negative(0)  Positive(1)  y_pred\n",
      "0        0.999997     0.000003     0.0\n",
      "1        0.999998     0.000002     0.0\n",
      "2        0.130568     0.869432     1.0\n",
      "3        0.999974     0.000026     0.0\n",
      "4        0.999972     0.000028     0.0\n",
      "...           ...          ...     ...\n",
      "1099     0.999993     0.000007     0.0\n",
      "1100     0.970131     0.029869     0.0\n",
      "1101     0.999985     0.000015     0.0\n",
      "1102     0.999999     0.000001     0.0\n",
      "1103     0.999970     0.000030     0.0\n",
      "\n",
      "[1104 rows x 3 columns]\n",
      "단일 모델 results :      thresholds         models  Accuracy  Precision  Recall  F1 score  \\\n",
      "0.1         0.1  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.2         0.2  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.3         0.3  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.4         0.4  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.5         0.5  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.6         0.6  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.7         0.7  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.8         0.8  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.9         0.9  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "\n",
      "     Auc_Score  \n",
      "0.1   0.348004  \n",
      "0.2   0.348004  \n",
      "0.3   0.348004  \n",
      "0.4   0.348004  \n",
      "0.5   0.348004  \n",
      "0.6   0.348004  \n",
      "0.7   0.348004  \n",
      "0.8   0.348004  \n",
      "0.9   0.348004  \n",
      "     thresholds         models  Accuracy  Precision  Recall  F1 score  \\\n",
      "0.1         0.1  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.2         0.2  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.3         0.3  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.4         0.4  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.5         0.5  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.6         0.6  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.7         0.7  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.8         0.8  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "0.9         0.9  XGBClassifier     0.974        0.0     0.0       0.0   \n",
      "\n",
      "     Auc_Score  \n",
      "0.1   0.348004  \n",
      "0.2   0.348004  \n",
      "0.3   0.348004  \n",
      "0.4   0.348004  \n",
      "0.5   0.348004  \n",
      "0.6   0.348004  \n",
      "0.7   0.348004  \n",
      "0.8   0.348004  \n",
      "0.9   0.348004  \n",
      "모델명: RandomForestClassifier\n",
      "학습 데이터 최적 파라미터\n",
      ": {'max_depth': 7, 'min_samples_split': 5}\n",
      "학습 데이터 최고 정확도\n",
      ": 0.983\n",
      "      Negative(0)  Positive(1)  y_pred\n",
      "0        0.999046     0.000954     0.0\n",
      "1        1.000000     0.000000     0.0\n",
      "2        0.339513     0.660487     1.0\n",
      "3        0.903187     0.096813     0.0\n",
      "4        0.999046     0.000954     0.0\n",
      "...           ...          ...     ...\n",
      "1099     0.969316     0.030684     0.0\n",
      "1100     0.710384     0.289616     0.0\n",
      "1101     0.999918     0.000082     0.0\n",
      "1102     0.990291     0.009709     0.0\n",
      "1103     1.000000     0.000000     0.0\n",
      "\n",
      "[1104 rows x 3 columns]\n",
      "단일 모델 results :      thresholds                  models  Accuracy  Precision  Recall  \\\n",
      "0.1         0.1  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.2         0.2  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.3         0.3  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.4         0.4  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.5         0.5  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.6         0.6  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.7         0.7  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.8         0.8  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.9         0.9  RandomForestClassifier     0.979        0.0     0.0   \n",
      "\n",
      "     F1 score  Auc_Score  \n",
      "0.1       0.0   0.372051  \n",
      "0.2       0.0   0.372051  \n",
      "0.3       0.0   0.372051  \n",
      "0.4       0.0   0.372051  \n",
      "0.5       0.0   0.372051  \n",
      "0.6       0.0   0.372051  \n",
      "0.7       0.0   0.372051  \n",
      "0.8       0.0   0.372051  \n",
      "0.9       0.0   0.372051  \n",
      "     thresholds                  models  Accuracy  Precision  Recall  \\\n",
      "0.1         0.1  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.2         0.2  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.3         0.3  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.4         0.4  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.5         0.5  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.6         0.6  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.7         0.7  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.8         0.8  RandomForestClassifier     0.979        0.0     0.0   \n",
      "0.9         0.9  RandomForestClassifier     0.979        0.0     0.0   \n",
      "\n",
      "     F1 score  Auc_Score  \n",
      "0.1       0.0   0.372051  \n",
      "0.2       0.0   0.372051  \n",
      "0.3       0.0   0.372051  \n",
      "0.4       0.0   0.372051  \n",
      "0.5       0.0   0.372051  \n",
      "0.6       0.0   0.372051  \n",
      "0.7       0.0   0.372051  \n",
      "0.8       0.0   0.372051  \n",
      "0.9       0.0   0.372051  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Auc_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     thresholds                  models  Accuracy  Precision  Recall  \\\n",
       "0.1         0.1           XGBClassifier     0.974        0.0     0.0   \n",
       "0.1         0.1  RandomForestClassifier     0.979        0.0     0.0   \n",
       "\n",
       "     F1 score  Auc_Score  \n",
       "0.1       0.0   0.348004  \n",
       "0.1       0.0   0.372051  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, accuracy_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression,  LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# df = pd.DataFrame(columns =['models','Accuracy','Precision', 'Recall', 'F1 score','Auc_Score'])\n",
    "\n",
    "\n",
    "\n",
    "class Model_Optimization():\n",
    "\n",
    "      def __init__(self):\n",
    "            \n",
    "            global model_df\n",
    "            model_df = pd.DataFrame(columns =['thresholds','models','Accuracy','Precision', 'Recall', 'F1 score','Auc_Score']) \n",
    "\n",
    "\n",
    "      #최적 파라미터 찾는 함수 ()\n",
    "      def grid(self,model_name, X_train=X_resampled_std, y_train=y_resampled_std, X_test=X_transition_17,y_test=y_transition_17):\n",
    "            global model_df\n",
    "\n",
    "            self.model_name = model_name\n",
    "            self.X_test = X_test\n",
    "            self.y_test = y_test\n",
    "            self.X_train = X_train\n",
    "            self.y_train  = y_train\n",
    "\n",
    "            if model_name == \"DecisionTreeClassifier\":\n",
    "                  dt = DecisionTreeClassifier()\n",
    "                  parameters = [{\"max_depth\": [3,5,7], \"min_samples_split\":[3,5,7]}]\n",
    "                  \n",
    "            elif model_name == \"RandomForestClassifier\":\n",
    "                  dt = RandomForestClassifier()\n",
    "                  parameters = [{\"max_depth\": [3,5,7], \"min_samples_split\":[3,5,7]}]\n",
    "                  \n",
    "            elif model_name == \"LogisticRegression\":\n",
    "                  dt = LogisticRegression()\n",
    "                  parameters = {'penalty':['l2', 'l1'],\n",
    "                  'C':[0.01, 0.1, 1, 5, 10]}\n",
    "                  \n",
    "            elif model_name == \"Linear SVM\": \n",
    "                  dt = SVC(probability=True)\n",
    "                  parameters = [{'kernel':['linear'], 'C':[0.001, 0.01, 0.025, 0.1, 1, 10, 100]}]\n",
    "                  \n",
    "            elif model_name == \"RBF SVM\": \n",
    "                  dt = SVC(probability=True)\n",
    "                  parameters = [{'gamma':[0.001, 0.01, 0.1, 1, 10, 100],'kernel':['rbf'],'C':[0.001, 0.01, 0.025, 0.1, 1, 10, 100]}]\n",
    "\n",
    "            elif model_name == \"AdaBoostClassifier\":\n",
    "                  dt= AdaBoostClassifier(random_state=0)\n",
    "                  parameters={'n_estimators':[5]}\n",
    "                  \n",
    "            elif model_name == \"GradientBoostingClassifier\":\n",
    "                  dt=GradientBoostingClassifier(random_state=0)\n",
    "                  parameters = {\n",
    "                  'n_estimators' : [100, 500],\n",
    "                  'learning_rate' : [0.05, 0.1]\n",
    "                              }\n",
    "\n",
    "            elif model_name == \"XGBClassifier\":\n",
    "                  dt=XGBClassifier(random_state=0,verbose=1)\n",
    "                  parameters={'n_estimators':[100, 500], 'learning_rate':[0.05, 0.1], 'max_depth':[3,4]}\n",
    "                  \n",
    "            # elif model_name == \"LGBMClassifier\":\n",
    "            #       dt=LGBMClassifier(random_state=0)\n",
    "            #       parameters={'n_estimators':[400,800], 'learning_rate':[0.05, 0.1] , 'max_depth':[3,4]}\n",
    "            \n",
    "            elif model_name == \"KNeighborsClassifier\":\n",
    "                  dt = KNeighborsClassifier()\n",
    "                  parameters = {'n_neighbors':[3]}\n",
    "                  \n",
    "            elif model_name == 'MLPClassifier':\n",
    "                  dt = MLPClassifier(random_state=0)\n",
    "                  parameters={'max_iter':[1000], 'hidden_layer_sizes':[1], 'activation':['logistic'],\n",
    "                              'solver':['sgd'], 'alpha':[0.01], 'batch_size':[32],\n",
    "                              'learning_rate_init':[0.1], 'max_iter':[500]}\n",
    "                  \n",
    "            elif model_name == 'GaussianProcessClassifier':\n",
    "                  dt = GaussianProcessClassifier(random_state=0)\n",
    "                  parameters={'kernel': [1.0*RBF(1.0)]}\n",
    "                  \n",
    "            elif model_name == 'GaussianNB':\n",
    "                  dt = GaussianNB()\n",
    "                  parameters={}\n",
    "                  \n",
    "            elif model_name =='QuadraticDiscriminantAnalysis':\n",
    "                  #선형판별분석\n",
    "                  dt = QuadraticDiscriminantAnalysis()\n",
    "                  parameters={}\n",
    "                  \n",
    "            # 최적 파라미터 찾기 \n",
    "            self.grid_dt  = GridSearchCV(dt, param_grid = parameters, cv=5, refit =True, n_jobs=-1)\n",
    "            self.grid_dt.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            print(f\"모델명: {model_name}\")\n",
    "            print(f\"학습 데이터 최적 파라미터\\n: {self.grid_dt.best_params_}\")\n",
    "            print(f\"학습 데이터 최고 정확도\\n: {self.grid_dt.best_score_:.3f}\")\n",
    "\n",
    "            #지도학습 알고리즘 \n",
    "            estimator = self.grid_dt.best_estimator_\n",
    "            y_pred = pd.DataFrame(estimator.predict(self.X_test))\n",
    "            y_pred_probability = pd.DataFrame(estimator.predict_proba(self.X_test))\n",
    "            # print(f\"예측 정확도\\n: {accuracy_score(self.y_test, y_pred):.3f}\")\n",
    "\n",
    "            prediction = pd.concat([y_pred_probability, y_pred], axis = 1)\n",
    "\n",
    "            prediction.columns = [\"Negative(0)\", \"Positive(1)\", \"y_pred\"]\n",
    "\n",
    "            print(prediction)\n",
    "            self.pred_proba_1 = np.array(prediction[\"Positive(1)\"]).reshape(-1, 1)\n",
    "            self.accuracy= round(accuracy_score(self.y_test, y_pred),3)\n",
    "            self.FPRs, self.TPRs, self.thresholds = roc_curve(self.y_test, self.pred_proba_1)\n",
    "            \n",
    "            return estimator\n",
    "\n",
    "\n",
    "\n",
    "      # 단일 모델 임계치별 score 출력 하는 함수 *주의  self.thresholds 값 내부 리스트 수정해줘야함 \n",
    "      def get_thresholds_score(self):\n",
    "            global model_df\n",
    "\n",
    "            \n",
    "            self.thresholds = [0.1, 0.2 , 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "            #평가지표용 리스트생성\n",
    "            precisions = []\n",
    "            recalls = []\n",
    "            f1_scores = []\n",
    "            auc_scores=[]\n",
    "            threshold_ =[]\n",
    "            \n",
    "            \n",
    "            \n",
    "            for threshold in self.thresholds:\n",
    "                  binarizer = Binarizer(threshold= threshold)\n",
    "                  # print(threshold)\n",
    "                  # 임계점 지정하여 Binariazer() 객체 생성\n",
    "                  pred_proba = binarizer.fit_transform(self.pred_proba_1)\n",
    "                  # print(pred_proba)\n",
    "                  # 임계점을 기준으로 데이터 변환\n",
    "\n",
    "                  precision = precision_score(self.y_test, pred_proba)\n",
    "                  recall = recall_score(self.y_test, pred_proba)\n",
    "                  f1score = f1_score(self.y_test, pred_proba)\n",
    "                  auc_score=roc_auc_score(self.y_test, self.pred_proba_1)\n",
    "\n",
    "                  precisions.append(precision)\n",
    "                  recalls.append(recall)\n",
    "                  f1_scores.append(f1score)\n",
    "                  auc_scores.append(auc_score)\n",
    "                  threshold_.append(threshold)\n",
    "                  \n",
    "\n",
    "            results = pd.DataFrame(data = {\"thresholds\":threshold_, \"models\":self.model_name,\"Accuracy\":self.accuracy,\"Precision\": precisions,\n",
    "                                          \"Recall\": recalls,\n",
    "                                          \"F1 score\": f1_scores,\"Auc_Score\":auc_scores}, index = self.thresholds)                 \n",
    "\n",
    "            print(f'단일 모델 results : {results}')      \n",
    "            return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      #모든 모델 성능 비교 함수 \n",
    "      def get_model_socre(self,input_list):\n",
    "            global model_df \n",
    "\n",
    "            mod = Model_Optimization()\n",
    "            for i in tqdm(input_list):\n",
    "                  mod.grid(model_name=i)\n",
    "                  results_df = mod.get_thresholds_score()\n",
    "\n",
    "                  #평가지표 데이터 프레임화 \n",
    "                  print(results_df)\n",
    "                  #기준 평가지표로 정렬\n",
    "                  results_df.sort_values(\"F1 score\", ascending=False, inplace=True)\n",
    "                  new_model_df= results_df.iloc[:1]\n",
    "                  model_df = pd.concat([model_df,new_model_df])\n",
    "                  \n",
    "            return model_df\n",
    "        \n",
    "list = ['XGBClassifier','RandomForestClassifier']\n",
    "model = Model_Optimization()\n",
    "model.get_model_socre(list)\n",
    "model_df.to_csv('../Data/result/2017년_확장.csv',index=False, encoding='cp949')\n",
    "\n",
    "model_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be8cf7e9ad931632694a3fc747a17e7acd2912bf0dbf0b287b5e4772507435a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
